[["index.html", "OPTAIN CS-10 Chapter 1 Introduction", " OPTAIN CS-10 Moritz Shore, Csilla Farkas 2023-05-19 Chapter 1 Introduction This is the documentation for the OPTAIN-CS10 Project. It is currently incomplete. Click the Arrow on the right to continue! "],["model-setup-with-swatbuildr.html", "Chapter 2 Model setup with SWATBuildR 2.1 High-Resolution Digital Elevation Model (DEM) 2.2 Processing the Basin Boundary 2.3 Processing the Land layer 2.4 Processing the Channels 2.5 Processing the DEM 2.6 Processing soil data 2.7 Calculating land unit connectivity 2.8 Calculating channel/reservoir connectivity 2.9 Terrain properties 2.10 Generate land object SWAT+ input tables 2.11 Generate water object SWAT+ input tables 2.12 Build aquifer input 2.13 Add point source inputs 2.14 Create SWAT+ sqlite database 2.15 TODO 2.16 Link aquifers and channels with geomorphic flow", " Chapter 2 Model setup with SWATBuildR The OPTAIN project is using the COCOA approach (ref!) schurz2022 and as such, needs to use the SWATBuildR package to calculate the connectivity between HRUs in the catchment. This chapter covers this process. We will define the location of our project here: project_path &lt;- &#39;model_data/cs10_setup&#39; And give it the name: project_name &lt;- &#39;optain-cs10&#39; Much of this documentation has been lost to time. We will need the following packages for this chapter: require(mapview) require(sf) require(raster) require(dplyr) # dplyr must be loaded after SF to avoid conflict If this flag is set to true, the markdown file will actually run buildR, which could take about 4 hours! run_code = FALSE 2.1 High-Resolution Digital Elevation Model (DEM) The high-resolution DEM is the basis for calculation of water connectivity, among other things. Most of the documentation of the creation of the DEM for CS10 has been lost to the sands of time. All we know is that it is located here: dem_path &lt;- &quot;model_data/input/elevation/dtm3_ns_v5.tif&quot; plot(raster(dem_path), main = &quot;CS10 DEM, UTM32N&quot;) To our knowledge, it has a 10 meter resolution. 1 meter resolution was available but there seems to have been issues with using it. It is definitely preferable to use the 1m DEM as certain important information can be lost with (max allowed resolution) of 10m. An example of a hydrologically effective landscape features being lost due to coarse DEM resolution. From(Schürz et al. 2022) 2.2 Processing the Basin Boundary The basin boundary has presumably been created using the defined outlet point of the catchment and the DEM. No more is currently known about this file other than that it is located here: bound_path &lt;- &quot;model_data/input/shape/cs10_basin.shp&quot; We will begin using the SWATBuildR Package by initializing its functions. (Note: this package is currently unfinished, which is why this step is necessary). The following code and commentary is from version 1.5.12, written by Christoph Schuerz. Another note: there are currently issues with White box which are being resolved. source(&#39;model_data/swat_buildR/init.R&#39;) BuildR recommends all layers to be in the same CRS, if we set project_layer to FALSE, it will throw an error when this is not the case: The input layers might be in different coordinate reference systems (CRS). It is recommended to project all layers to the same CRS and check them before using them as model inputs. The model setup process checks if the layer CRSs differ from the one of the basin boundary. By setting ‘proj_layer &lt;- TRUE’ the layer is projected if the CRS is different. If FALSE different CRS trigger an error. project_layer &lt;- TRUE We read in and check the basin boundary and run some checks bound &lt;- read_sf(bound_path) %&gt;% select() set_proj_crs(bound, data_path) check_polygon_topology(layer = bound, data_path = data_path, label = &#39;basin&#39;, n_feat = 1, checks = c(F,T,T,T,F,F,F,F)) 2.3 Processing the Land layer Our land layer is located here: land_path &lt;- &quot;model_data/input/land/CS10_LU.shp&quot; Documentation on its creation does not exist. Interactive land use map of CS10 by Farm ID We had an issue with the classification of the land uses. For the OPTAIN project, all agricultural fields must have a unique ID, and our land uses only had the ID of the given farm KGB (which had many different fields). To remedy this, new IDs were generated with the format a_###f_# where a_ represents the farm, and f_ represents the respective field of that farm. The farm names needed to be shortened because the SWAT+ model often cannot handle long ID names (longer than 16 characters) Note, the potential measures polygons were not counted as individual fields, which is why SP_ID does not match up with field_ID – This is by design. readr::read_csv(&quot;model_data/farm_id/a_f_id.csv&quot;, show_col_types = F) %&gt;% head() ## # A tibble: 6 × 4 ## KGB type_fr sp_id field_ID ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 213/8/1 a_084 1 a_084f_1 ## 2 213/7/6 a_083 2 a_083f_1 ## 3 213/7/6 a_083 3 a_083f_2 ## 4 213/7/4 a_082 4 a_082f_1 ## 5 213/65/1 a_081 5 a_081f_1 ## 6 213/65/1 a_081 6 a_081f_2 This was done in a simple QGIS workflow of dissolving by farm, splitting from single part to multipart, and then adding an iterating ID per farm field. This workflow could be replicated in R, and then shown here. It is under consideration… This is our map with the new type IDs. lu_map &lt;- mapview(read_sf(land_path), zcol = &quot;type&quot;, legend = FALSE) lu_map Interactive land use map of CS10 by Field ID BuildR will now run some checks on our land layer. land &lt;- read_sf(land_path) %&gt;% check_layer_attributes(., type_to_lower = FALSE) %&gt;% check_project_crs(layer = ., data_path = data_path, proj_layer = project_layer, label = &#39;land&#39;, type = &#39;vector&#39;) check_polygon_topology(layer = land, data_path = data_path, label = &#39;land&#39;, area_fct = 0.00, cvrg_frc = 99.9, checks = c(T,F,T,T,T,T,T,T)) BuildR splits the land layer into HRU (land) and reservoir (water) objects split_land_layer(data_path) 2.4 Processing the Channels No documentation exists on the source of the channels layer, all we know is that it is located here: channel_path &lt;- &#39;model_data/input/line/cs10_channels.shp&#39; channels &lt;- read_sf(channel_path) %&gt;% dplyr::select(&quot;type&quot;) plot(channels) BuildR runs some checks: channel &lt;- read_sf(channel_path) %&gt;% check_layer_attributes(., type_to_lower = TRUE) %&gt;% check_project_crs(layer = ., data_path = data_path, proj_layer = project_layer, label = &#39;channel&#39;, type = &#39;vector&#39;) check_line_topology(layer = channel, data_path = data_path, label = &#39;channel&#39;, length_fct = 0, can_cross = FALSE) And gives this output: channels &lt;- read_sf(&quot;model_data/cs10_setup/optain-cs10/data/vector/channel.shp&quot;) channel_map &lt;- mapview(channels, zcol = &quot;type&quot;) bound_map+channel_map BuildR then checks the connectivity between the channels and reservoirs. For this we need to define our id_cha_out and id_res_out. Variable id_cha_out sets the outlet point of the catchment. Either define a channel OR a reservoir as the final outlet. If channel then assign id_cha_out with the respective id from the channel layer. If reservoir then assign the respective id from the land layer to id_res_out, otherwise leave as NULL id_cha_out &lt;- 37 id_res_out &lt;- NULL Running connectivity checks between channels and reservoirs: check_cha_res_connectivity(data_path, id_cha_out, id_res_out) Checking if any defined channel ids for drainage from land objects do not exist check_land_drain_ids(data_path) 2.5 Processing the DEM BuildR loads and checks the DEM, and saves it. dem &lt;- rast(dem_path) %&gt;% check_project_crs(layer = ., data_path = data_path, proj_layer = project_layer, label = &#39;dem&#39;, type = &#39;raster&#39;) check_raster_coverage(rst = dem, vct_layer = &#39;land&#39;, data_path = data_path, label = &#39;dem&#39;, cov_frc = 0.95) save_dem_slope_raster(dem, data_path) 2.6 Processing soil data Our soil map is located here: soil_layer_path &lt;- &#39;model_data/input/soil/soil_layer.tif&#39; No documentation exists on its creation. The soil data and lookup path are located here: soil_lookup_path &lt;- &#39;model_data/input/soil/soil_lookup.csv&#39; soil_data_path &lt;- &#39;model_data/input/soil/UserSoil_Krakstad.csv&#39; Not much documentation exists here either. Some can be found in the excel sheet: ## [1] &quot;model_data/input/soil/swatsoil2.xlsx&quot; BuildR reads in the soil data, performs checks, processes, and saves. NOTE: THIS IS CURRENTLY BROKEN, WITH ERROR MESSAGE: Warning: Cannot find coordinate operations from EPSG:2583 [“unnamed”,EDATUM[“”], CS[Cartesian,2], AXIS[“(E)”, east, ORDER[1], LENGTHUNIT[“unknown”, 1]], AXIS[“(N)”, north, ORDER[2], LENGTHUNIT[“unknown”, 1]]]’ (GDAL error 6) Error: [project] Cannot do this transformation soil &lt;- rast(soil_layer_path) %&gt;% check_project_crs(layer = ., data_path = data_path, proj_layer = project_layer, label = &#39;soil&#39;, type = &#39;raster&#39;) check_raster_coverage(rst = soil, vct_layer = &#39;hru&#39;, data_path = data_path, label = &#39;soil&#39;, cov_frc = 0.75) # BROKEN #save_soil_raster(soil, data_path) # added soil.tif from back when it used to work BuildR then generates a table with aggregated elevation, slope, soil for HRU units. # waiting on soil fix. #aggregate_hru_dem_soil(data_path) Read and prepare the soil input tables and a soil/hru id table and write them into data_path/tables.sqlite #build_soil_data(soil_lookup_path, soil_data_path, data_path) 2.7 Calculating land unit connectivity Preparing raster layers based on the DEM and the surface channel objects that will be used in the calculation of the land object connectivity. #prepare_terrain_land(data_path) The connection of each land object to neighboring land and water objects is calculated based on the flow accumulation and the D8 flow pointer along the object edge # calculate_land_connectivity(data_path) 2.7.1 Eliminate land object connections with small flow fractions: For each land object the flow fractions are compared to connection with the largest flow fraction of that land object. Connections are removed if their fraction is smaller than frc_thres relative to the largest one. This is necessary to: Simplify the connectivity network To reduce the risk of circuit routing between land objects. Circuit routing will be checked. If an error due to circuit routing is triggered, then ‘frc_thres’ must be increased to remove connectivities that may cause this issue. frc_thres &lt;- 0.3 The remaining land object connections are analyzed for infinite loop routing. For each land unit the connections are propagated and checked if the end up again in the same unit. #reduce_land_connections(data_path, frc_thres) %&gt;% # check_infinite_loops(., data_path, &#39;Land&#39;) If infinite loops were identified this routine tries to resolve the issues by selectively removing connections between land units in order to get rid of all infinite loops. # resolve_loop_issues(data_path) 2.8 Calculating channel/reservoir connectivity 2.8.1 Calculating the water object connectivity the function returns the cha and res con_out tables in SWAT+ database format and writes them into data_path/tables.sqlite #build_water_object_connectivity(data_path) 2.8.2 Checking the water objects for infinite loops From the cha_res_con_out tables id_from/id_to links are generated and checked for infinite loop routing. #prepare_water_links(data_path) %&gt;% # check_infinite_loops(., data_path, &#39;Water&#39;, Inf) 2.9 Terrain properties Calculate terrain properties such as elevation, slope, catchment area, channel width/depth for channel and reservoir objects and write them into data_path/tables.sqlite #prepare_terrain_water(data_path) 2.10 Generate land object SWAT+ input tables Build the landuse.lum and a landuse/hru id table and write them into data_path/tables.sqlite #build_landuse(data_path) Build the HRU SWAT+ input files and write them into data_path/tables.sqlite #build_hru_input(data_path) Add wetlands to the HRUs and build the wetland input files and write them into data_path/tables.sqlite (TODO fix this!) wetland_landuse &lt;- c(&#39;wehb&#39;, &#39;wetf&#39;, &#39;wetl&#39;, &#39;wetn&#39;) #add_wetlands(data_path, wetland_landuse) 2.11 Generate water object SWAT+ input tables Build the SWAT+ cha input files and write them into data_path/tables.sqlite #build_cha_input(data_path) Build the SWAT+ res input files and write them into data_path/tables.sqlite #build_res_input(data_path) Build SWAT+ routing unit con_out based on ‘land_connect_fraction’. #build_rout_con_out(data_path) Build the SWAT+ rout_unit input files and write them into data_path/tables.sqlite #build_rout_input(data_path) Build the SWAT+ LSU input files and write them into data_path/tables.sqlite #build_ls_unit_input(data_path) 2.12 Build aquifer input Build the SWAT+ aquifer input files for a single aquifer for the entire catchment. The connectivity to the channels with geomorphic flow must be added after writing the txt input files. This is not implemented in the script yet. #build_single_aquifer_files(data_path) 2.13 Add point source inputs The point source locations are provided with a point vector layer in the path ‘point_path’. point_path &lt;- &#39;model_data/input/point/cs10_pointsource.shp&#39; point_sf &lt;- read_sf(point_path) point_map &lt;- mapview(point_sf, zcol = &quot;GRAD_P&quot;, cex = &quot;GRAD_N&quot;) point_map+channel_map+bound_map Map of point sources, colored by (assumed) phosphorous and size by (assumed) Nitrogren Maximum distance of a point source to a channel or a reservoir to be included as a point source object (recall) in the model setup: max_point_dist &lt;- 500 #meters Point source records can automatically be added from files in the same folder as the point source location layer. To be identified as point source data the files must be named as &lt;name&gt;_&lt;interval&gt;.csv, where &lt;name&gt; must be the name of a point int the vector layer and &lt;interval&gt; must be one of const, yr, mon, or day depending on the time intervals in the input data. #add_point_sources(point_path, data_path, max_point_dist) 2.14 Create SWAT+ sqlite database 2.14.1 Write the SWAT+Editor project database The database will be located the ‘project_path’. After writing the database it can be opened and edited with the SWAT+Editor. #create_swatplus_database(project_path, project_name) The next step involves you entering the SWAT+ Editor and parameterizing the model from there. These are the steps we have taken, with screenshots since it is currently not possible to replicate this process in R. 2.15 TODO Switch to SWAT+Editor for further model parametrization and continue with the step below after writing the SWAT+ projects’ text input files 2.16 Link aquifers and channels with geomorphic flow A SWATbuildR model setup only has one single aquifer (in its current version). This aquifer is linked with all channels through a channel- aquifer-link file (aqu_cha.lin) in order to maintain recharge from the aquifer into the channels using the geomorphic flow option of SWAT+ The required input file cannot be written with the SWAT+Editor. Therefore it has to be generated in a step after writing the model text input files with the SWAT+Editor. Path of the TxtInOut folder (project folder where the SWAT+ text files are written with the SWAT+Editor) txt_path &lt;- &#39;../swat_runs/txtinouit/&#39; #link_aquifer_channels(txt_path) References "],["climate-inputs-and-weather-generator.html", "Chapter 3 Climate inputs and weather generator 3.1 Preperation and loading data 3.2 Creating the weather generator", " Chapter 3 Climate inputs and weather generator 3.1 Preperation and loading data To add weather and climate data to our SWAT project, we will use svatools 3.1.1 Required packages require(euptf2) # devtools::install_github(&quot;tkdweber/euptf2&quot;) require(svatools) # devtools::install_github(&quot;biopsichas/svatools&quot;) require(readr) require(readxl) require(sf) require(mapview) 3.1.2 Load in the file(s) and load svatools template First we load in the template and fill it in with our values and rename it to “cs10_weather_data.xlsx”. This is not done within R. #temp_path &lt;- system.file(&quot;extdata&quot;, &quot;weather_data.xlsx&quot;, package = &quot;svatools&quot;) # /// fill out this template and save &quot;cs10_weather_data.xlsx&quot; /// We are using the following projection for this project: epgs_code = 25832 Now we can load it in with Svatools. met_lst &lt;- load_template(template_path = &quot;model_data/input/met/cs10_weather_data.xlsx&quot;, epgs_code) ## [1] &quot;Loading data from template.&quot; ## [1] &quot;Reading station ID1 data.&quot; ## [1] &quot;Loading of data is finished.&quot; 3.1.3 Proof the station plot_weather(met_lst, &quot;PCP&quot;, &quot;month&quot;, &quot;sum&quot;) Checking the location of the station: basin_path &lt;- &quot;model_data/input/shape/cs10_basin.shp&quot; basin &lt;- st_transform(st_read(basin_path), epgs_code) %&gt;% mutate(NAME = &quot;Basin&quot;) ## Reading layer `cs10_basin&#39; from data source ## `C:\\Users\\mosh\\Documents\\GitHub\\NIBIO\\optain-cs10\\model_data\\input\\shape\\cs10_basin.shp&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 1 feature and 1 field ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: 603439.4 ymin: 6607792 xmax: 610984.4 ymax: 6622017 ## Projected CRS: ETRS89 / UTM zone 32N stations &lt;- st_transform(met_lst$stations, epgs_code) mapview(stations) + mapview(basin) 3.2 Creating the weather generator We only have one weather station, which means only one weather generator. wgn &lt;- prepare_wgn(met_lst, TMP_MAX = met_lst$data$ID1$TMP_MAX, TMP_MIN = met_lst$data$ID1$TMP_MIN, PCP = met_lst$data$ID1$PCP, RELHUM = met_lst$data$ID1$RELHUM, WNDSPD = met_lst$data$ID1$WNDSPD, MAXHHR = met_lst$data$ID1$MAXHHR, SLR = met_lst$data$ID1$SLR) ## [1] &quot;Coordinate system checked and transformed to EPSG:4326.&quot; ## [1] &quot;Working on station ID1:WS_AAS&quot; write.csv(wgn$wgn_st, &quot;model_data/input/met/as_wgn_st.csv&quot;, row.names = FALSE, quote = FALSE) write.csv(wgn$wgn_data, &quot;model_data/input/met/as_wgn_data.csv&quot;, row.names = FALSE, quote = FALSE) "],["adding-weather-data-to-swat-project.html", "Chapter 4 Adding weather data to SWAT project", " Chapter 4 Adding weather data to SWAT project Currently, this throws an error – Cannot tell why, but might not be an issue because it still writes the files that we need. Because the buildR script is currently broken, we cannot evaluate the following code db_path &lt;- &quot;model_data/cs10_setup/optain-cs10/...sqlite&quot; add_weather(db_path, met_lst, wgn) "],["crop-map-generations.html", "Chapter 5 Crop map generations 5.1 Farm and field area 5.2 Generate crop map from farm data 5.3 Extrapolating the crop rotation 5.4 Joining the land layer with the crop rotation data", " Chapter 5 Crop map generations As OPTAIN takes into account the individual field, we need to know what is growing on which field and when. Unfortunately our data foundation for this task is quite lackluster, but we will try out best to do so. in the following chapter. require(sf) require(dplyr) require(readr) require(stringr) require(mapview) require(readxl) require(reshape2) require(tibble) require(DT) 5.1 Farm and field area We have data based on what area certain crops have per farm. In order to relate this to our spatial land use map, we require the area of both the farms, and the fields within these farms. The basis for these calculations comes from the BuildR output: (REF header here) lu_sf &lt;- read_sf(&quot;model_data/cs10_setup/optain-cs10/data/vector/land.shp&quot;) lu_map &lt;- mapview(lu_sf, zcol = &quot;type&quot;) lu_map 5.1.1 Calculate Farm area and assign IDs This stage has been completed in QGIS. An R-implementation is being considered. farm_area_sf &lt;- read_sf(&quot;model_data/input/crop/buildr_output_dissolved_into_farms.shp&quot;) farm_area_map &lt;- mapview(farm_area_sf, zcol = &quot;farm_id&quot;) farm_area_map 5.1.2 Calculate Field area and assign IDs This stage has been completed in QGIS. An R-implementation is being considered. field_area_sf &lt;- read_sf(&quot;model_data/input/crop/buildr_output_dissolved_into_fields.shp&quot;) field_area_map &lt;- mapview(field_area_sf, zcol = &quot;type&quot;) field_area_map 5.2 Generate crop map from farm data The following algorithm takes information from reporting farm, and their respective area in the SWAT+ setup, and combines these data sets to generate a plausible crop rotation. Note, pasture refers to meadow (TODO: fix!) crop_data &lt;- read_excel(&quot;model_data/input/crop/crop_rotation_source_data.xlsx&quot;) datatable(crop_data) 5.2.1 Tidy up the source data: We are converting the source data to tidy format in the following code snippet crop_names &lt;- melt( crop_data, id.vars = c(&quot;farm_id&quot;, &quot;year&quot;, &quot;area_daa&quot;, &quot;pastrure_area_daa&quot;), measure.vars = c(&quot;crop1&quot;, &quot;crop2&quot;, &quot;crop3&quot;), variable.name = &quot;crop_status&quot;, value.name = &quot;crop&quot; ) %&gt;% tibble() crop_area &lt;- melt( crop_data, id.vars = c(&quot;farm_id&quot;, &quot;year&quot;, &quot;area_daa&quot;, &quot;pastrure_area_daa&quot;), measure.vars = c(&quot;percent_crop1&quot;, &quot;percent_crop2&quot;, &quot;percent_crop3&quot;), variable.name = &quot;crop_status&quot;, value.name = &quot;area&quot; ) %&gt;% tibble() crop_area$crop_status &lt;- crop_area$crop_status %&gt;% str_remove(&quot;percent_&quot;) # unstable, TODO fix! colnames(crop_area)[6] &lt;- &quot;crop_area_percent&quot; crop_tidy &lt;- left_join(crop_names, crop_area, by = c(&quot;farm_id&quot;, &quot;year&quot;, &quot;area_daa&quot;,&quot;pastrure_area_daa&quot;, &quot;crop_status&quot;)) %&gt;% dplyr::select(-crop_status) # unstable, TODO fix! colnames(crop_tidy)[3] &lt;- &quot;farm_area_daa&quot; crop_tidy$crop_area_percent &lt;- (crop_tidy$crop_area_percent/100) %&gt;% round(2) crop_tidy &lt;- crop_tidy %&gt;% filter(crop %&gt;% is.na() == FALSE) datatable(crop_tidy) 5.2.2 Tidy up the BuildR output The maps shown in secttion (ref) were exported to CSV in QGIS. An R-implementation might be written in here sometime (#TODO). This CSV data needs to be re-formatted to be tidy as well. fields &lt;- read_csv( &quot;model_data/input/crop/buildr_landuse_dissolved_into_fields.csv&quot;, show_col_types = F ) %&gt;% dplyr::select(type, farm_id, field_area_daa) farms &lt;- read_csv( &quot;model_data/input/crop/buildr_landuse_dissolved_into_farms.csv&quot;, show_col_types = F ) %&gt;% dplyr::select(type, farm_id , farm_area_) # fix farm_area_ # unstable, fix! colnames(farms)[3] &lt;- &quot;farm_area_daa&quot; farms$farm_area_daa &lt;- farms$farm_area_daa %&gt;% round(2) fields$field_area_daa &lt;- fields$field_area_daa %&gt;% round(2) reported_data &lt;- left_join(fields, farms, by = &quot;farm_id&quot;) # unstable, fix! colnames(reported_data)[1] &lt;- &quot;field_id&quot; reported_data &lt;- reported_data %&gt;% dplyr::select(field_id, farm_id, field_area_daa, farm_area_daa) datatable(reported_data) 5.2.3 Field classification We are now ready to perform our classification. We will store our results in this predefined dataframe: classed_fields &lt;- tibble( farm_id = NA, field_id = NA, farm_area_daa = NA, field_area_daa = NA, crop = NA, year = NA ) The following reporting farms will be used for the classification: farms &lt;- reported_data$farm_id %&gt;% unique() For the following years (AKA we have data for these years): years &lt;- c(2016, 2017, 2018, 2019) This for loop runs through all the fields and classifies them. The output will not be printed in this file, but will be saved in a log file, that you can dig out of the repository, located here: #TODO add the log file generation The following code is not executed: # For every year for(c_year in years){ # For every farm, for (farm in farms) { # Do the following: # Filter the source and buildR data to the given year and farm crop_filter &lt;- crop_tidy %&gt;% filter(year == c_year) %&gt;% filter(farm_id == farm) hru_filter &lt;- reported_data %&gt;% filter(farm_id == farm) # Behavior if the farm has no reporting data: if(crop_filter$farm_id %&gt;% length() == 0){ # Set all fields to winter wheat. farm_fields &lt;- hru_filter %&gt;% dplyr::select(farm_id, field_id, farm_area_daa, field_area_daa) %&gt;% arrange(desc(field_area_daa)) farm_fields$crop = &quot;wwht&quot; farm_fields$year = c_year # Add them to the results dataframe classed_fields &lt;- rbind(classed_fields, farm_fields) # and skipping to next farm next() } # Behavior, if there is reporting data on the farm&quot; # Find the area of the farm (all elements in vector are the same, so ok # to just grab the first) farm_area_hru &lt;- hru_filter$farm_area_daa[1] # Find the discrepency between &quot;SHOULD BE&quot; crop area and &quot;CURRENTLY IS&quot; # crop area. We want this as an absolute value. area_dis &lt;- (hru_filter$farm_area_daa[1]-crop_filter$farm_area_daa[1]) %&gt;% round(2) %&gt;% abs() # Some farms have no reported area. in this case we set it to some random # negative number. if(area_dis %&gt;% is.na()){area_dis = -999} # Extracting the area of the pasture and farm (all vectors same value, ok # to just take the first) past_area &lt;- crop_filter$pastrure_area_daa[1] farm_area &lt;- crop_filter$farm_area_daa[1] # Extract relevant fields farm_fields &lt;- hru_filter %&gt;% dplyr::select(farm_id, field_id, farm_area_daa, field_area_daa) %&gt;% # and sort by area arrange(desc(field_area_daa)) # pre-define crops column to be NA farm_fields$crop = NA # Bollean check to see if the field has been meadow in a previous year. If # it has, then we want to continue planting meadow on it (This was a # decision we made.) has_meadow &lt;- (classed_fields %&gt;% filter(field_id %in% farm_fields$field_id) %&gt;% filter(crop == &quot;meadow&quot;) %&gt;% dplyr::select(field_id) %&gt;% pull() %&gt;% length() &gt; 0) ### Determining how much land the crops should cover. # This if statement checks if is currently a pasture portion for the reporting # farm, or if there has been in the past. if((past_area %&gt;% is.na() == FALSE) | has_meadow) { # If it does, or did, then this special routine is enacted: # Determines the pasture percentage of the total farm past_percent &lt;- (past_area/farm_area) # If it cannot be calculated, then it is set to 0 if(past_percent %&gt;% is.na()){past_percent = 0} # The crop fractions provided to us in the source data did not account for # the pasture fraction. therefore we need to reduce the other crop # fractions by this amount. adjuster &lt;- past_percent / length(crop_filter$crop) crop_filter$crop_area_percent &lt;- crop_filter$crop_area_percent-adjuster # creating a new entry for pasture and adding it to the now updated crop\\ # fractions list past_row &lt;- tibble( farm_id = farm, year = c_year, farm_area_daa = crop_filter$farm_area_daa[1], pastrure_area_daa = past_area, crop = &quot;meadow&quot;, crop_area_percent = past_percent ) crop_filter &lt;- rbind(crop_filter, past_row) # Creating an updated &quot;SHOULD BE&quot; and &quot;CURRENTLY IS&quot; crop coverage # datafram crop_coverage &lt;- tibble( crop = crop_filter$crop, to_cover = (farm_area_hru*crop_filter$crop_area_percent)) # Setting the initial actual coverage to 0 (&quot;CURRENTLY IS&quot;) crop_coverage$actual &lt;- 0 # This extracts the fields that were previously pasture fields. previously_pasture &lt;- classed_fields %&gt;% filter(field_id %in% farm_fields$field_id) %&gt;% filter(crop == &quot;meadow&quot;) %&gt;% dplyr::select(field_id) %&gt;% pull() if (length(previously_pasture) &gt; 0) { # if some of the fields were previously pasture, they are set to pasture # again: farm_fields$crop[ which(farm_fields$field_id %in% previously_pasture)] = &quot;meadow&quot; # We save the amount of area the meadow crops cover, so that we can # adjust the other &quot;SHOULD BE&quot; fractions correctly. custom_actual &lt;- farm_fields %&gt;% filter(crop == &quot;meadow&quot;) %&gt;% dplyr::select(field_area_daa) %&gt;% pull() %&gt;% sum(na.rm = T) crop_coverage$actual[which(crop_coverage$crop==&quot;meadow&quot;)] = custom_actual } # Now the algorithm continues as normal. # This is the routine that is run, when no meadow is detected: }else{ # creating a tibble which tracks how much land the crops SHOULD cover crop_coverage &lt;- tibble( crop = crop_filter$crop, to_cover = (farm_area_hru * crop_filter$crop_area_percent) ) # pre define crop coverage to 0 (CURRENT) crop_coverage$actual &lt;- 0 } ### Crop classification # Now we know how much land the crops SHOULD cover, it is time to assign # the fields accordingly. We do this with a WHILE loop, which keeps going # until we have classified every field. while(any(farm_fields$crop %&gt;% is.na())){ # run through all the crops in the crop coverage list and determine or # update their current coverage for (c_crop in crop_coverage$crop) { # figure out which index we are in the list crop_index &lt;- which(c_crop == crop_coverage$crop) # Determine/UPDATE the current actual coverage of the crop (sum) crop_coverage$actual[crop_index] &lt;- farm_fields %&gt;% filter(crop == c_crop) %&gt;% dplyr::select(field_area_daa) %&gt;% sum() } # Calculate the difference between crop SHOULD BE coverage and ACTUAL # coverage crop_coverage$diff &lt;- crop_coverage$actual-crop_coverage$to_cover # determine the maximum difference. max_diff &lt;- crop_coverage$diff %&gt;% min(na.rm = T) # determine which crop has the maximum difference max_diff_crop &lt;- crop_coverage$crop[which(crop_coverage$diff == max_diff) %&gt;% min(na.rm = T)] # determine the biggest field left un-classified. biggest_na_field &lt;- farm_fields %&gt;% filter(crop %&gt;% is.na()) %&gt;% arrange(desc(field_area_daa)) %&gt;% nth(1) # Set the field which is still NA, and also the biggest to the crop with # the maximum difference (This code seems weird, and could be # improved?) farm_fields$crop[which((farm_fields$crop %&gt;% is.na() == TRUE) &amp; farm_fields$field_area_daa == biggest_na_field$field_area_daa )] &lt;- max_diff_crop } # After having classified the field, we update the actual coverage value # the respective crop that has been classified. for (c_crop in crop_coverage$crop) { crop_index &lt;- which(c_crop == crop_coverage$crop) crop_coverage$actual[crop_index] &lt;- farm_fields %&gt;% filter(crop == c_crop) %&gt;% dplyr::select(field_area_daa) %&gt;% sum() } # save the year of this crop assignment in the dataframe farm_fields$year = c_year # add the classification to the result dataframe classed_fields &lt;- rbind(classed_fields, farm_fields) # and move onto the next farm } # for every year } # Remove the first NA line classed_fields &lt;- classed_fields[-1, ] Now we can have a look at our results (not evaluated) datatable(classed_fields) We can now extract the crop rotation from this datatable. (not evaluated) # the format of our final dataframe final_df &lt;- tibble(field = NA, y_2016 = NA, y_2017 = NA, y_2018 = NA, y_2019 = NA) # fields we need to extract field_ids &lt;- classed_fields$field_id %&gt;% unique() We will do this with this for loop (note this is bad R-practice. Should be done with something like pivot_longer (TODO)) for(c_field_id in field_ids) { crop_rotation &lt;- tibble(field = c_field_id) crops &lt;- classed_fields %&gt;% filter(field_id == c_field_id) %&gt;% dplyr::select(crop) %&gt;% t() %&gt;% as_tibble(.name_repair = &quot;minimal&quot;) colnames(crops) &lt;- c(&quot;y_2016&quot;, &quot;y_2017&quot;, &quot;y_2018&quot;, &quot;y_2019&quot;) crop_rotation &lt;- cbind(crop_rotation, crops) %&gt;% as_tibble() final_df &lt;- rbind(final_df, crop_rotation) } # Remove the first NA line crop_rotation &lt;- final_df[-1,] # Save the crop rotation in CSV format write_csv(x = crop_rotation, file = &quot;model_data/input/crop/cs10_crop_rotation.csv&quot;) 5.3 Extrapolating the crop rotation For OPTAIN, the crop rotation needs to span from 1988 to 2020. We currently have 2016 to 2019. crop_rotation &lt;- read_csv(&quot;model_data/input/crop/cs10_crop_rotation.csv&quot;, show_col_types = F) rotation &lt;- crop_rotation %&gt;% dplyr::select(-field) crop_rotation_extrapolated &lt;- cbind(crop_rotation, rotation, rotation, rotation, rotation, rotation, rotation, rotation, rotation$y_2016) # set the column names to be in the correct format colnames(crop_rotation_extrapolated) &lt;- c(&quot;field&quot;, paste0(&quot;y_&quot;, 1988:2020)) 5.4 Joining the land layer with the crop rotation data The output of SWATbuildR “land.shp” needs to be connected to the newly generated crop map. lu &lt;- read_sf(&quot;model_data/cs10_setup/optain-cs10/data/vector/land.shp&quot;) # temporary rename to field, for the left join # unstable, fix! colnames(lu)[2] = &quot;field&quot; # join the crop rotation and land use layer by their field ID lu_cr &lt;- left_join(lu, crop_rotation_extrapolated, by = &quot;field&quot; ) # reset column name. # unstable, fix! colnames(lu_cr)[2] = &quot;lu&quot; # Write the new shape file write_sf(lu_cr, &quot;model_data/input/crop/land_with_cr.shp&quot;) "],["landuse.lum-update.html", "Chapter 6 Landuse.lum update 6.1 Data preperation 6.2 Setting cal_group 6.3 Setting plnt_com 6.4 Setting mgt 6.5 Setting urb_ro 6.6 Setting urban 6.7 Setting Manning’s n (ovn)", " Chapter 6 Landuse.lum update This section covers the modifications made to the landuse file. For some reason it was written in a tutorial fashion, as if the reader were new to R. We require tidyverse for this since we will be using many of its functions. require(tidyverse) require(reshape2) require(sf) require(DT) require(dplyr) # require dplyr last to overwrite plyr coun() 6.1 Data preperation We read in the land use file. We want to set skip = 1 to ignore the SWAT+editor text, and set header = T. We then convert it to a tibble format for better printing to console landuse_lum &lt;- read.table(&quot;model_data/cs10_setup/temp_landuse.lum&quot;, skip = 1, header = T) %&gt;% tibble::as_tibble() (#tab:lum_tab)The landuse.lum file, post BuildR name cal_group plnt_com mgt cn2 cons_prac urban urb_ro ov_mann tile sep vfs grww bmp a_001f_1_drn_lum null nopl_comm null null null null null null mw24_1000 null null null null a_001f_2_drn_lum null nopl_comm null null null null null null mw24_1000 null null null null a_001f_3_drn_lum null nopl_comm null null null null null null mw24_1000 null null null null a_001f_4_drn_lum null nopl_comm null null null null null null mw24_1000 null null null null a_001f_5_drn_lum null nopl_comm null null null null null null mw24_1000 null null null null a_001f_6_drn_lum null nopl_comm null null null null null null mw24_1000 null null null null a_001f_7_drn_lum null nopl_comm null null null null null null mw24_1000 null null null null a_002f_1_drn_lum null nopl_comm null null null null null null mw24_1000 null null null null a_002f_2_drn_lum null nopl_comm null null null null null null mw24_1000 null null null null a_002f_3_drn_lum null nopl_comm null null null null null null mw24_1000 null null null null Our field_id for our cropland does not match name of landuse_lum so we need to parse it out, we can do this many ways, but a safe way is to split it by “_” and combine the first 3 splits with that same underscore: splitted &lt;- landuse_lum$name %&gt;% str_split(&quot;_&quot;) landuse_lum$field_id &lt;- paste(splitted %&gt;% map(1), splitted %&gt;% map(2), splitted %&gt;% map(3), sep = &quot;_&quot;) head(landuse_lum$field_id) ## [1] &quot;a_001f_1&quot; &quot;a_001f_2&quot; &quot;a_001f_3&quot; &quot;a_001f_4&quot; &quot;a_001f_5&quot; &quot;a_001f_6&quot; But wait, this does not work for our “non-fields”. So lets find out which ones they are, and set them to NA not_fields &lt;- which(!grepl(x=landuse_lum$field_id, &quot;a_&quot;)) landuse_lum$field_id[not_fields] &lt;- NA So, what non-fields do we have? landuse_lum$name[not_fields] ## [1] &quot;frst_lum&quot; &quot;past_lum&quot; &quot;rngb_lum&quot; &quot;urml_lum&quot; &quot;utrn_lum&quot; &quot;wetf_lum&quot; Good to know. We’ll keep that in mind. 6.2 Setting cal_group There is no info on this column, so we are going to leave it as null. 6.3 Setting plnt_com This step will be done by SWATFarmR (ref that header here!) 6.4 Setting mgt This step will be done by SWATFarmR (ref that header here!) 6.5 Setting urb_ro We want to set the urb_ro column for all urban land uses (in our case this would be urml and utrn) to usgs_reg. We can do this like so: landuse_lum$urb_ro[which(landuse_lum$name %in% c(&quot;urml_lum&quot;, &quot;utrn_lum&quot;))] &lt;- &quot;usgs_reg&quot; (#tab:urbro_tab)Changing urb_ro in the landuse file name cal_group plnt_com mgt cn2 cons_prac urban urb_ro ov_mann tile sep vfs grww bmp field_id urml_lum null null null null null null usgs_reg null null null null null null NA utrn_lum null null null null null null usgs_reg null null null null null null NA Very good. In our case this was only two – could be done by hand, but that will not be the case for all of our land uses. 6.6 Setting urban This one is easy, we set our urban column to an urban parameter set of the same name. The rest we leave as null landuse_lum$urban[which(landuse_lum$name ==&quot;utrn_lum&quot;)] &lt;- &quot;utrn&quot; landuse_lum$urban[which(landuse_lum$name ==&quot;urml_lum&quot;)] &lt;- &quot;urml&quot; (#tab:urbro_tab2)Changing urban in the landuse file name cal_group plnt_com mgt cn2 cons_prac urban urb_ro ov_mann tile sep vfs grww bmp field_id urml_lum null null null null null urml usgs_reg null null null null null null NA Lets make sure other land uses still have null: Table 6.1: Landuse frst in the landuse file name cal_group plnt_com mgt cn2 cons_prac urban urb_ro ov_mann tile sep vfs grww bmp field_id frst_lum null nopl_comm null null null null null null null null null null null NA Looks good. 6.7 Setting Manning’s n (ovn) Lets get the easy ones out of the way landuse_lum$ov_mann[which(landuse_lum$name ==&quot;past_lum&quot;)] &lt;- &quot;densegrass&quot; landuse_lum$ov_mann[which(landuse_lum$name ==&quot;rngb_lum&quot;)] &lt;- &quot;rangeland_20cover&quot; landuse_lum$ov_mann[which(landuse_lum$name ==&quot;urml_lum&quot;)] &lt;- &quot;urban_rubble&quot; landuse_lum$ov_mann[which(landuse_lum$name ==&quot;urtn_lum&quot;)] &lt;- &quot;urban_asphalt&quot; Don’t fall asleep yet! For wetf we want forest_heavy but with a higher value. this means we need to add a new entry. And since we are doing this fancy Rmarkdown stuff, we’re going to do it with code! Lets jump in and get at this file. (REMEBER TO REMOVE THE TEMP) ovn_table_path &lt;- &quot;model_data/cs10_setup/temp_ovn_table.lum&quot; ovn_table &lt;- readLines(ovn_table_path) Good, now where is this forest heavy entry? and what does the format look like? index &lt;- grepl(x=ovn_table, &quot;forest_heavy&quot;) %&gt;% which %&gt;% min() ovn_table[c(2, index)] %&gt;% print() ## [1] &quot;name ovn_mean ovn_min ovn_max description&quot; ## [2] &quot;forest_heavy 0.80000 0.70000 0.90000 Forest_heavy&quot; Now, lets make our own and add it in. But only if it doesn’t exist it (Like if the script has been run before…) if(grepl(x = ovn_table, &quot;forest_heavy_cs10&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;forest_heavy_cs10 0.90000 0.80000 0.95000 Forest_heavy_mod&quot; ovn_table &lt;- c(ovn_table, entry) } Did it work? Yes: ovn_table %&gt;% tail() ## [1] &quot;forest_med 0.60000 0.50000 0.70000 Forest_medimum_good&quot; ## [2] &quot;forest_heavy 0.80000 0.70000 0.90000 Forest_heavy&quot; ## [3] &quot;urban_asphalt 0.01100 0.01100 0.01100 Urban_asphalt&quot; ## [4] &quot;urban_concrete 0.01200 0.01200 0.01200 Urban_concrete&quot; ## [5] &quot;urban_rubble 0.02400 0.02400 0.02400 Urban_rubble&quot; ## [6] &quot;forest_heavy_cs10 0.90000 0.80000 0.95000 Forest_heavy_mod&quot; Now lets write this new table writeLines(ovn_table, con = ovn_table_path) And now we can enter our wetland class: landuse_lum$ov_mann[which(landuse_lum$name ==&quot;wetf_lum&quot;)] &lt;- &quot;forest_heavy_cs10&quot; For the fields we are going to need the crop rotation info which we created in section (!ref) crop_rotation &lt;- read_csv(&quot;model_data/input/crop/cs10_crop_rotation.csv&quot;, show_col_types = F) head(crop_rotation) ## # A tibble: 6 × 5 ## field y_2016 y_2017 y_2018 y_2019 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a_025f_1 wwht wwht wwht wwht ## 2 a_025f_3 wwht wwht wwht wwht ## 3 a_025f_4 wwht wwht wwht wwht ## 4 a_025f_2 wwht wwht wwht wwht ## 5 a_105f_1 wwht wwht wwht wwht ## 6 a_105f_4 wwht wwht wwht wwht We have decided to classify ovn based on the degree to which a crop rotation contains meadow, conventional crops (wwht, pota), and conservation crops (all others). To do this we need to analyze the crop rotation. Now it gets a little complicated, but trust me its not actually as bad as it looks. We need to count how many times certain crops show up in the crop rotation of a certain field. Lets do it for conventional crops first. Now, lets get into it conv_crop_count &lt;- crop_rotation %&gt;% melt(. ,&quot;field&quot;) %&gt;% group_by(field) %&gt;% filter(value %in% c(&quot;wwht&quot;, &quot;pota&quot;)) %&gt;% dplyr::count() %&gt;% dplyr::rename(conv = n) head(conv_crop_count) ## # A tibble: 6 × 2 ## # Groups: field [6] ## field conv ## &lt;chr&gt; &lt;int&gt; ## 1 a_001f_1 4 ## 2 a_001f_2 4 ## 3 a_001f_3 4 ## 4 a_001f_4 4 ## 5 a_001f_5 4 ## 6 a_001f_6 4 What happened here? well we took our crop_rotation, and melted it by field using melt. This function converts the data into tidy format (ref). This format makes it easier to apply the following operations on a field basis. What does this look like? crop_rotation %&gt;% melt(. ,&quot;field&quot;) %&gt;% arrange(field) %&gt;% head() ## field variable value ## 1 a_001f_1 y_2016 wwht ## 2 a_001f_1 y_2017 wwht ## 3 a_001f_1 y_2018 wwht ## 4 a_001f_1 y_2019 wwht ## 5 a_001f_2 y_2016 wwht ## 6 a_001f_2 y_2017 wwht melt is a function from reshape2 which is why we required it. And what does that “.” mean in there, to the left of \"field\"?? That is a code word for the object to the left of the “pipe” (in this case crop_rotation). the pipe is “%&gt;%” and passes the object to the left of it, into the function to the right of it. look it up! (!ref) When arranged by field, we can see that every field gets one entry per crop per year. This is a good format to count how many times we have a certain type of crop on a field. Next we group_by the field – this means all the following operations will be done on a field basis. Then we filter our value (which is the crop name). For conventional we needed to filter in any fields with the crop \"wwht\" or \"pota\". What does this look like? crop_rotation %&gt;% melt(. ,&quot;field&quot;) %&gt;% group_by(field) %&gt;% filter(value %in% c(&quot;wwht&quot;, &quot;pota&quot;)) ## # A tibble: 1,519 × 3 ## # Groups: field [415] ## field variable value ## &lt;chr&gt; &lt;fct&gt; &lt;chr&gt; ## 1 a_025f_1 y_2016 wwht ## 2 a_025f_3 y_2016 wwht ## 3 a_025f_4 y_2016 wwht ## 4 a_025f_2 y_2016 wwht ## 5 a_105f_1 y_2016 wwht ## 6 a_105f_4 y_2016 wwht ## 7 a_105f_2 y_2016 wwht ## 8 a_105f_3 y_2016 wwht ## 9 a_187f_1 y_2016 wwht ## 10 a_206f_1 y_2016 wwht ## # ℹ 1,509 more rows Looks good. We only have crops with winter wheat and potatoes, for every year. Exactly what we need, now we just need to count() them. conv_crop_count &lt;- crop_rotation %&gt;% melt(. ,&quot;field&quot;) %&gt;% group_by(field) %&gt;% filter(value %in% c(&quot;wwht&quot;, &quot;pota&quot;)) %&gt;% dplyr::count() head(conv_crop_count) ## # A tibble: 6 × 2 ## # Groups: field [6] ## field n ## &lt;chr&gt; &lt;int&gt; ## 1 a_001f_1 4 ## 2 a_001f_2 4 ## 3 a_001f_3 4 ## 4 a_001f_4 4 ## 5 a_001f_5 4 ## 6 a_001f_6 4 And we are back where we started! See, not that complicated. One last thing we need to do is rename n to conv, we do that like so: conv_crop_count &lt;- crop_rotation %&gt;% melt(. ,&quot;field&quot;) %&gt;% group_by(field) %&gt;% filter(value %in% c(&quot;wwht&quot;, &quot;pota&quot;)) %&gt;% dplyr::count() %&gt;% dplyr::rename(conv = n) head(conv_crop_count) ## # A tibble: 6 × 2 ## # Groups: field [6] ## field conv ## &lt;chr&gt; &lt;int&gt; ## 1 a_001f_1 4 ## 2 a_001f_2 4 ## 3 a_001f_3 4 ## 4 a_001f_4 4 ## 5 a_001f_5 4 ## 6 a_001f_6 4 Now lets go ahead and do the same thing for the two other categories: cons andmeadow. meadow_crop_count &lt;- crop_rotation %&gt;% melt(. ,&quot;field&quot;) %&gt;% group_by(field) %&gt;% filter(value == &quot;meadow&quot; ) %&gt;% dplyr::count() %&gt;% dplyr::rename(meadow = n) cons_crop_count &lt;- crop_rotation %&gt;% melt(. ,&quot;field&quot;) %&gt;% group_by(field) %&gt;% filter(!(value %in% c(&quot;wwht&quot;, &quot;pota&quot;, &quot;meadow&quot;))) %&gt;% dplyr::count() %&gt;% dplyr::rename(cons = n) cons_crop_count %&gt;% head() ## # A tibble: 6 × 2 ## # Groups: field [6] ## field cons ## &lt;chr&gt; &lt;int&gt; ## 1 a_002f_1 2 ## 2 a_002f_2 2 ## 3 a_002f_3 4 ## 4 a_002f_4 4 ## 5 a_002f_5 2 ## 6 a_002f_6 4 meadow_crop_count %&gt;% head() ## # A tibble: 6 × 2 ## # Groups: field [6] ## field meadow ## &lt;chr&gt; &lt;int&gt; ## 1 a_012f_3 4 ## 2 a_012f_6 4 ## 3 a_016f_3 4 ## 4 a_017f_2 4 ## 5 a_017f_3 4 ## 6 a_046f_1 4 meadow was a simple filter, all we have to do was grab crops with the meadow name. For cons crops, we just grabbed the remaining crops that were not conv or meadow. Great. We have these 3 separate, we need to combine them. we can do that with left_join and join by the field column which contains our IDs # create a base dataframe to join to crop_fractions &lt;- crop_rotation %&gt;% dplyr::select(field) %&gt;% distinct() # join our 3 data frames crop_fractions &lt;- left_join(crop_fractions, conv_crop_count, by = &quot;field&quot;) crop_fractions &lt;- left_join(crop_fractions, cons_crop_count, by = &quot;field&quot;) crop_fractions &lt;- left_join(crop_fractions, meadow_crop_count, by = &quot;field&quot;) # lets have a look crop_fractions %&gt;% head() ## # A tibble: 6 × 4 ## field conv cons meadow ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 a_025f_1 4 NA NA ## 2 a_025f_3 4 NA NA ## 3 a_025f_4 4 NA NA ## 4 a_025f_2 4 NA NA ## 5 a_105f_1 4 NA NA ## 6 a_105f_4 4 NA NA That does not look good! when it seems like when the count is 0, it is returned as NA. Lets fix that… crop_fractions &lt;- crop_fractions %&gt;% mutate(cons = ifelse(is.na(cons), 0, cons)) crop_fractions &lt;- crop_fractions %&gt;% mutate(conv = ifelse(is.na(conv), 0, conv)) crop_fractions &lt;- crop_fractions %&gt;% mutate(meadow = ifelse(is.na(meadow), 0, meadow)) What are we doing here? we are mutating the the 3 columns using an ifelse statement. The statement is simple. If the value is.na then we set it to 0. Otherwise, we set it to the same value it had before. did it work? crop_fractions %&gt;% head() ## # A tibble: 6 × 4 ## field conv cons meadow ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 a_025f_1 4 0 0 ## 2 a_025f_3 4 0 0 ## 3 a_025f_4 4 0 0 ## 4 a_025f_2 4 0 0 ## 5 a_105f_1 4 0 0 ## 6 a_105f_4 4 0 0 Very good. Now we need to decide what to classify our fields at. lets Define some functions to do that. is_meadow &lt;- function(conv, cons, meadow) { ((meadow &gt; cons) &amp; (meadow &gt; conv)) %&gt;% return() } is_cons &lt;- function(conv, cons, meadow) { ((cons &gt;= meadow) &amp; (cons &gt; conv)) %&gt;% return() } is_conv &lt;- function(conv, cons, meadow) { ((conv &gt;= meadow) &amp; (conv &gt;= cons)) %&gt;% return() } The &amp; sign means that both conditions need to be met. and &gt;= you should know already. Lets use those functions in action. lets do the meadow first. We will create a new dataframe from crop fractions, named field_class. field_class &lt;- crop_fractions %&gt;% mutate(meadow = is_meadow(conv,cons,meadow)) head(field_class) ## # A tibble: 6 × 4 ## field conv cons meadow ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; ## 1 a_025f_1 4 0 FALSE ## 2 a_025f_3 4 0 FALSE ## 3 a_025f_4 4 0 FALSE ## 4 a_025f_2 4 0 FALSE ## 5 a_105f_1 4 0 FALSE ## 6 a_105f_4 4 0 FALSE Ok, so none of those first 6 fields are meadow dominated. What about cons? (lets stick with our field_class dataframe and just keep adding on) field_class &lt;- field_class %&gt;% mutate(cons = is_cons(conv,cons,meadow)) head(field_class) ## # A tibble: 6 × 4 ## field conv cons meadow ## &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;lgl&gt; ## 1 a_025f_1 4 FALSE FALSE ## 2 a_025f_3 4 FALSE FALSE ## 3 a_025f_4 4 FALSE FALSE ## 4 a_025f_2 4 FALSE FALSE ## 5 a_105f_1 4 FALSE FALSE ## 6 a_105f_4 4 FALSE FALSE Nope, not cons either. Then it must be conv dominant. field_class &lt;- field_class %&gt;% mutate(conv = is_conv(conv,cons,meadow)) field_class %&gt;% head() ## # A tibble: 6 × 4 ## field conv cons meadow ## &lt;chr&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt; ## 1 a_025f_1 TRUE FALSE FALSE ## 2 a_025f_3 TRUE FALSE FALSE ## 3 a_025f_4 TRUE FALSE FALSE ## 4 a_025f_2 TRUE FALSE FALSE ## 5 a_105f_1 TRUE FALSE FALSE ## 6 a_105f_4 TRUE FALSE FALSE Correct! now lets just double check that we didnt have any cases where all are TRUE or where all are FALSE field_class %&gt;% dplyr::select(conv, cons, meadow) %&gt;% isTRUE %&gt;% all() ## [1] FALSE field_class %&gt;% dplyr::select(conv, cons, meadow) %&gt;% isFALSE() %&gt;% all() ## [1] FALSE Looks good to me! carry on: We have our field classifications now, they will be very useful to us later. Lets pull them out of our dataframe to store them as a nice list. cons_fields &lt;- field_class %&gt;% filter(cons) %&gt;% dplyr::select(field) %&gt;% pull() conv_fields &lt;- field_class %&gt;% filter(conv) %&gt;% dplyr::select(field) %&gt;% pull() meadow_fields &lt;- field_class %&gt;% filter(meadow) %&gt;% dplyr::select(field) %&gt;% pull() cons_fields %&gt;% head() ## [1] &quot;a_182f_1&quot; &quot;a_182f_5&quot; &quot;a_182f_3&quot; &quot;a_182f_4&quot; &quot;a_182f_2&quot; &quot;a_182f_7&quot; conv_fields %&gt;% head() ## [1] &quot;a_025f_1&quot; &quot;a_025f_3&quot; &quot;a_025f_4&quot; &quot;a_025f_2&quot; &quot;a_105f_1&quot; &quot;a_105f_4&quot; meadow_fields %&gt;% head() ## [1] &quot;a_182f_6&quot; &quot;a_182f_8&quot; &quot;a_017f_3&quot; &quot;a_017f_2&quot; &quot;a_012f_3&quot; &quot;a_012f_6&quot; Fantastic! Now that was a big task, but it makes the next bit very easy. Lets assign the correct ovn to the types of fields we have classified: 6.7.0.0.0.1 Agricultural Fields: Meadow landuse_lum$ov_mann[which(landuse_lum$field_id %in% meadow_fields)] &lt;- &quot;shortgrass&quot; 6.7.0.0.0.2 Agricultural Fields: Conventional landuse_lum$ov_mann[which(landuse_lum$field_id %in% conv_fields)] &lt;- &quot;convtill_nores&quot; 6.7.0.0.0.3 Agricultural Fields: Conservational landuse_lum$ov_mann[which(landuse_lum$field_id %in% cons_fields)] &lt;- &quot;falldisk_res&quot; 6.7.0.1 Forest Now all we need to do is the forest. We have decided we want forest_heavy on good soils, and forest_light on poor soils… you know what that means! We need to get geo-spatial! We are going to need our soil data, lets load in it: soil_map &lt;- &quot;model_data/input/soil/soil_map_UTM32N.shp&quot; soil_map_shp &lt;- read_sf(soil_map) This file is messy, but we can see our soil names are in the column “SNAM” soil_map_shp$SNAM %&gt;% head() ## [1] &quot;Humic&quot; &quot;Sea_dep_thick&quot; &quot;End_moraine&quot; &quot;Sea_dep_thin&quot; ## [5] &quot;End_moraine&quot; &quot;Humic&quot; # we only need to keep the soil name, ID, and its geometry. soil_map_shp &lt;- soil_map_shp %&gt;% dplyr::select(SOIL_ID, SNAM, geometry) Ok so we’ve got our spatial data loaded in, just for fun, lets have a look at this soil IDs: plot(soil_map_shp[&quot;SOIL_ID&quot;], main = &quot;CS10 Soil map&quot;) Sweet. But we also need to know where our landuses are… So lets open the file SWATbuildR has prepared for us: lu_map &lt;- &quot;model_data/cs10_setup/optain-cs10/data/vector/land.shp&quot; lu_map_shp &lt;- read_sf(lu_map) plot(lu_map_shp[&quot;type&quot;], main = &quot;CS10 Landuse&quot;) Ok – we have the location of the land use, and the location of the soils, but we are interested in soil depth for classifying our forests into good and bad. Where can we find this data? usersoil.csv of course! in the column SOL_ZMX. Lets go get that usersoil_path &lt;- &quot;model_data/input/soil/UserSoil_Krakstad.csv&quot; usersoil &lt;- read_csv(usersoil_path, show_col_types = F) usersoil %&gt;% head() ## # A tibble: 6 × 152 ## OBJECTID MUID SEQN SNAM S5ID CMPPCT NLAYERS HYDGRP SOL_ZMX ANION_EXCL ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 324938 1 ARdy 0 100 4 C 1000 0.5 ## 2 2 324938 1 ARdy-tn 0 100 3 C 1000 0.5 ## 3 3 324938 1 Mountain 0 100 2 D 500 0.5 ## 4 4 324938 1 CMdy 0 100 4 C 1000 0.5 ## 5 5 324938 1 CMdy-ap 0 100 3 C 1000 0.5 ## 6 6 324938 1 CMdy-sl 0 100 3 C 1000 0.5 ## # ℹ 142 more variables: SOL_CRK &lt;dbl&gt;, TEXTURE &lt;chr&gt;, SOL_Z1 &lt;dbl&gt;, ## # SOL_BD1 &lt;dbl&gt;, SOL_AWC1 &lt;dbl&gt;, SOL_K1 &lt;dbl&gt;, SOL_CBN1 &lt;dbl&gt;, CLAY1 &lt;dbl&gt;, ## # SILT1 &lt;dbl&gt;, SAND1 &lt;dbl&gt;, ROCK1 &lt;dbl&gt;, SOL_ALB1 &lt;dbl&gt;, USLE_K1 &lt;dbl&gt;, ## # SOL_EC1 &lt;dbl&gt;, SOL_Z2 &lt;dbl&gt;, SOL_BD2 &lt;dbl&gt;, SOL_AWC2 &lt;dbl&gt;, SOL_K2 &lt;dbl&gt;, ## # SOL_CBN2 &lt;dbl&gt;, CLAY2 &lt;dbl&gt;, SILT2 &lt;dbl&gt;, SAND2 &lt;dbl&gt;, ROCK2 &lt;dbl&gt;, ## # SOL_ALB2 &lt;dbl&gt;, USLE_K2 &lt;dbl&gt;, SOL_EC2 &lt;dbl&gt;, SOL_Z3 &lt;dbl&gt;, SOL_BD3 &lt;dbl&gt;, ## # SOL_AWC3 &lt;dbl&gt;, SOL_K3 &lt;dbl&gt;, SOL_CBN3 &lt;dbl&gt;, CLAY3 &lt;dbl&gt;, SILT3 &lt;dbl&gt;, … Now, let us left_join the soil map with SOL_ZMX, by connecting the SOIL_ID. # we only need the soil name and depth soil_depth &lt;- usersoil %&gt;% dplyr::select(OBJECTID, SNAM, SOL_ZMX) # &quot;rename&quot; a column so that we have matching columns for the left_join soil_depth$SOIL_ID &lt;- soil_depth$OBJECTID soil_depth_map &lt;- dplyr::left_join(soil_map_shp, soil_depth, by = &quot;SOIL_ID&quot;) plot(soil_depth_map[&quot;SOL_ZMX&quot;], main = &quot;CS10 soil depth&quot;, key.pos = 1) Now, we need to connect our land use map to our soil depth map: soil_depth_map2 &lt;- soil_depth_map %&gt;% dplyr::select(SOIL_ID, SNAM.x, SOL_ZMX, geometry) # are the coordinate reference systems the same (TRUE?) st_crs(lu_map_shp) == st_crs(soil_depth_map) ## [1] TRUE joined_map &lt;- st_join(lu_map_shp, soil_depth_map2) Lets have a look at what we’ve got plot(joined_map[&quot;SOL_ZMX&quot;], main = &quot;CS10 Land Layer, soil depth (mm)&quot;) We are done with the geospatial analysis, so we can drop the geometries: lu_sol_depth &lt;- st_drop_geometry(joined_map) # and we only need to keep the ID (id), land use (type) and soil depth (SOL_ZMX) lu_soil &lt;- lu_sol_depth %&gt;% dplyr::select(id, type, SOL_ZMX) head(lu_soil) ## # A tibble: 6 × 3 ## id type SOL_ZMX ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 frst 150 ## 2 1 frst 1000 ## 3 1 frst 1000 ## 4 1 frst 800 ## 5 1 frst 1000 ## 6 1 frst 800 And this is the moment, dear reader… where our coder realized his big mistake: lu_soil %&gt;% dplyr::select(type) %&gt;% dplyr::filter(!grepl(x = type, &quot;a_&quot;)) %&gt;% unique() ## # A tibble: 7 × 1 ## type ## &lt;chr&gt; ## 1 frst ## 2 rngb ## 3 urml ## 4 utrn ## 5 past ## 6 watr ## 7 wetf require(crayon) cat(red(bold(italic(underline( &quot;We cant have good and bad forests based on soil types...\\n because we only have one forest land use type.. YOU FOOL!\\n&quot; ))))) Well that settles it then. We will just use forest_medium for all frst. We can only change this if we go back to buildR and define more generic forest classes. landuse_lum$ov_mann[which(landuse_lum$name ==&quot;frst_lum&quot;)] &lt;- &quot;forest_med&quot; 6.7.0.2 Summary With all that data processing out of the way, lets have a quick look at what we’ve done: landuse_lum$ov_mann[which(landuse_lum$name == &quot;past_lum&quot;)] &lt;- &quot;densegrass&quot; landuse_lum$ov_mann[which(landuse_lum$name == &quot;rngb_lum&quot;)] &lt;- &quot;rangeland_20cover&quot; landuse_lum$ov_mann[which(landuse_lum$name == &quot;urml_lum&quot;)] &lt;- &quot;urban_rubble&quot; landuse_lum$ov_mann[which(landuse_lum$name == &quot;urtn_lum&quot;)] &lt;- &quot;urban_asphalt&quot; landuse_lum$ov_mann[which(landuse_lum$name == &quot;frst_lum&quot;)] &lt;- &quot;forest_med&quot; landuse_lum$ov_mann[which(landuse_lum$field_id %in% meadow_fields)] &lt;- &quot;shortgrass&quot; landuse_lum$ov_mann[which(landuse_lum$field_id %in% conv_fields)] &lt;- &quot;convtill_nores&quot; landuse_lum$ov_mann[which(landuse_lum$field_id %in% cons_fields)] &lt;- &quot;falldisk_res&quot; landuse_lum$ov_mann[which(landuse_lum$name == &quot;wetf_lum&quot;)] &lt;- &quot;forest_heavy_cs10&quot; Sweet. Next column.. 6.7.1 Setting cn2: You know the drill – I am sure you know how to read this code by now. # Brush-brush-weed-grass_mixture_with_brush_the_major_element (poor) landuse_lum$cn2[which(landuse_lum$name == &quot;rngb_lum&quot;)] &lt;- &quot;brush_p&quot; # Woods (poor) landuse_lum$cn2[which(landuse_lum$name == &quot;wetf_lum&quot;)] &lt;- &quot;wood_p&quot; # Paved_streets_and_roads;_open_ditches_(incl._right-of-way) landuse_lum$cn2[which(landuse_lum$name == &quot;utrn_lum&quot;)] &lt;- &quot;paveroad&quot; # Paved_parking_lots_roofs_driveways_etc_(excl_right-of-way) landuse_lum$cn2[which(landuse_lum$name == &quot;urml_lum&quot;)] &lt;- &quot;urban&quot; # Woods (fair) landuse_lum$cn2[which(landuse_lum$name == &quot;frst_lum&quot;)] &lt;- &quot;wood_f&quot; # Pasture_grassland_or_range-continuous_forage_for_grazing landuse_lum$cn2[which(landuse_lum$name == &quot;past_lum&quot;)] &lt;- &quot;pastg_g&quot; # Meadow-continuous_grass_protected_from_grazing_mowed_for_hay landuse_lum$cn2[which(landuse_lum$field_id %in% meadow_fields)] &lt;- &quot;pasth&quot; # Row_crops landuse_lum$cn2[which(landuse_lum$field_id %in% cons_fields)] &lt;- &quot;rc_conterres_g&quot; # Row_crops landuse_lum$cn2[which(landuse_lum$field_id %in% conv_fields)] &lt;- &quot;rc_strow_p&quot; 6.7.2 Setting cons_prac For this, we need to add some custom entries to the database: # TODO: remove temp!!!! cons_prac_path &lt;- &quot;model_data/cs10_setup/temp_cons_practice.lum&quot; cons_prac &lt;- readLines(cons_prac_path) cons_prac[1:3] %&gt;% print() ## [1] &quot;cons_practice.lum: written by SWAT+ editor v2.1.0 on 2023-03-31 08:13 for SWAT+ rev.60.5.4&quot; ## [2] &quot;name usle_p slp_len_max description&quot; ## [3] &quot;up_down_slope 1.00000 121.00000 Up_and_down_slope&quot; Let us do it in a way so that it is only added if it doesn’t exist yet: if(grepl(x = cons_prac, &quot;agri_conv&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;agri_conv 1.00000 60.00000 no_convervation&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;agri_part_conv&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;agri_part_conv 0.85000 60.00000 75_percent_convential&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;agri_half&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;agri_half 0.70000 50.00000 50_percent_convential&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;agri_part_cons&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;agri_part_cons 0.50000 30.00000 75_percent_consveration&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;agri_cons&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;agri_cons 0.30000 30.00000 100_percent_consveration&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;past_cons&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;past_cons 0.1 60 pasture&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;rngb_cons&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;rngb_cons 0.2 60 rangeland&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;frst_cons&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;frst_cons 0.1 60 forest&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;urml_cons&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;urml_cons 1 60 cs10urban&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;utrn_cons&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;utrn_cons 1 60 road&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;cs10_meadow&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;cs10_meadow 0.2 60 cs10_meadow&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;wetf_cons&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;wetf_cons 0.05 30 wetlands&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;cs10_sed_pond&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;cs10_sed_pond 0.1 30 cs10_sed_pond&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;cs10_cons_wetl&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;cs10_cons_wetl 0.1 30 cs10_cons_wetl&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;cs10_buff_grass&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;cs10_buff_grass 0.25 10 cs10_buff_grass&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;cs_10_buff_wood&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;cs_10_buff_wood 0.2 10 cs_10_buff_wood&quot; cons_prac &lt;- c(cons_prac, entry) } And write the updated file: writeLines(cons_prac, con = cons_prac_path) Now we need to define the 0, 25, 50, 75, 100 percent conventional crops. We can use our old “crop_fractions” dataframe: head(crop_fractions) ## # A tibble: 6 × 4 ## field conv cons meadow ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 a_025f_1 4 0 0 ## 2 a_025f_3 4 0 0 ## 3 a_025f_4 4 0 0 ## 4 a_025f_2 4 0 0 ## 5 a_105f_1 4 0 0 ## 6 a_105f_4 4 0 0 Lets derive which fields get classified as what p100_conv &lt;- crop_fractions %&gt;% filter(conv==4) %&gt;% dplyr::select(field) %&gt;% pull() p75_conv &lt;- crop_fractions %&gt;% filter(conv==3) %&gt;% dplyr::select(field) %&gt;% pull() p50_conv &lt;- crop_fractions %&gt;% filter(conv==2) %&gt;% dplyr::select(field) %&gt;% pull() p25_conv &lt;- crop_fractions %&gt;% filter(conv==1) %&gt;% dplyr::select(field) %&gt;% pull() p0_conv &lt;- crop_fractions %&gt;% filter(conv==0) %&gt;% dplyr::select(field) %&gt;% pull() Now we can assign the all the land uses # Agricultural landuse_lum$cons_prac[which(landuse_lum$field_id %in% p100_conv)] &lt;- &quot;agri_conv&quot; landuse_lum$cons_prac[which(landuse_lum$field_id %in% p75_conv)] &lt;- &quot;agri_part_conv&quot; landuse_lum$cons_prac[which(landuse_lum$field_id %in% p50_conv)] &lt;- &quot;agri_half&quot; landuse_lum$cons_prac[which(landuse_lum$field_id %in% p25_conv)] &lt;- &quot;agri_part_cons&quot; landuse_lum$cons_prac[which(landuse_lum$field_id %in% p0_conv)] &lt;- &quot;agri_cons&quot; # Meadow landuse_lum$cons_prac[which(field_class$meadow)] &lt;- &quot;cs10_meadow&quot; # Generic landuse_lum$cons_prac[which(landuse_lum$name == &quot;past_lum&quot;)] &lt;- &quot;past_cons&quot; landuse_lum$cons_prac[which(landuse_lum$name == &quot;rngb_lum&quot;)] &lt;- &quot;rngb_cons&quot; landuse_lum$cons_prac[which(landuse_lum$name == &quot;frst_lum&quot;)] &lt;- &quot;frst_cons&quot; landuse_lum$cons_prac[which(landuse_lum$name == &quot;urml_lum&quot;)] &lt;- &quot;urml_cons&quot; landuse_lum$cons_prac[which(landuse_lum$name == &quot;utrn_lum&quot;)] &lt;- &quot;utrn_cons&quot; landuse_lum$cons_prac[which(landuse_lum$name == &quot;wetf_lum&quot;)] &lt;- &quot;wetf_cons&quot; # Measures landuse_lum$cons_prac[which(landuse_lum$name == &quot;cs10_sed_pond&quot;)] &lt;- &quot;cs10_sed_pond&quot; landuse_lum$cons_prac[which(landuse_lum$name == &quot;cs10_cons_wetl&quot;)] &lt;- &quot;cs10_cons_wetl&quot; landuse_lum$cons_prac[which(landuse_lum$name == &quot;cs10_buff_grass&quot;)] &lt;- &quot;cs10_buff_grass&quot; landuse_lum$cons_prac[which(landuse_lum$name == &quot;cs_10_buff_wood&quot;)] &lt;- &quot;cs_10_buff_wood&quot; 6.7.3 Setting tile This column has already been completed by SWATbuildR in (!ref) 6.7.4 Setting sep This column has been left as null 6.7.5 Setting vfs This column has been left as null 6.7.6 Setting grww This column has been left as null 6.7.7 Setting bmp This column has been left as null 6.7.8 Writing Changes We are done with our modifications however, we need to remove the field_id column landuse_lum &lt;- landuse_lum %&gt;% dplyr::select(-field_id) lets take a look at the final product: datatable(landuse_lum) Lets write out changes new_lum_path &lt;- &quot;model_data/cs10_setup/temp_lum_new.lum&quot; write.table(landuse_lum, file = new_lum_path, sep = &quot;\\t&quot;, quote = F, row.names = F) But wait – we need to keep that pesky header, otherwise the FarmR will be very angry with us. lum_lines &lt;- readLines(new_lum_path) header &lt;- &quot;header header header HEADER, delete me and you will regret it FOREVER!&quot; lum_lines2&lt;- c(header,lum_lines) writeLines(text = lum_lines2, con = new_lum_path) Done! "],["wip.html", "Chapter 7 WIP 7.1 Channel parameters revised 7.2 Crop parameters verified 7.3 Soil physical parameters in final form 7.4 Soil chemical parameters in final form 7.5 Impoundment parameters defined 7.6 Water diversions defined 7.7 Point sources parameters added 7.8 Tile drainage parameters defined 7.9 Atmospheric deposition defined 7.10 Additional settings verified", " Chapter 7 WIP 7.1 Channel parameters revised This an ongoing unresolved issue #49 7.2 Crop parameters verified 7.3 Soil physical parameters in final form 7.4 Soil chemical parameters in final form 7.5 Impoundment parameters defined 7.6 Water diversions defined 7.7 Point sources parameters added 7.8 Tile drainage parameters defined 7.9 Atmospheric deposition defined 7.10 Additional settings verified "]]
