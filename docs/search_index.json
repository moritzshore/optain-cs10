[["index.html", "OPTAIN CS-10 Chapter 1 Introduction", " OPTAIN CS-10 Moritz Shore, Csilla Farkas 2023-05-22 Chapter 1 Introduction This is the documentation for the OPTAIN-CS10 Project. It is currently a work in progress. "],["model-setup-with-swatbuildr.html", "Chapter 2 Model setup with SWATBuildR 2.1 Processing input data 2.2 Calculating Contiguous Object Connectivity 2.3 Generate SWAT+ input 2.4 Add point source inputs 2.5 Create SWAT+ sqlite database", " Chapter 2 Model setup with SWATBuildR The OPTAIN project is using the COCOA approach (ref!) schurz2022 and as such, needs to use the SWATBuildR package to calculate the connectivity between HRUs in the catchment. This chapter covers this process. We will define the location of our project here: project_path &lt;- &#39;model_data/cs10_setup&#39; And give it the name: project_name &lt;- &#39;optain-cs10&#39; Much of this documentation has been lost to time. We will need the following packages for this chapter: require(mapview) require(sf) require(raster) require(dplyr) # dplyr must be loaded after SF to avoid conflict require(ggplot2) sf_theme &lt;- theme(axis.text.x=element_blank(), #remove x axis labels axis.ticks.x=element_blank(), #remove x axis ticks axis.text.y=element_blank(), #remove y axis labels axis.ticks.y=element_blank() #remove y axis ticks ) If this flag is set to true, the markdown file will actually run buildR, which could take about 4 hours! run_code = FALSE 2.1 Processing input data SWATBuildR reads input data, performs some checks on it, and saves it in a compatible format for subsequent calculations. Little documentation exists on the creation of these data sets. IF you have any information to add, feel free to do so. 2.1.1 High-Resolution Digital Elevation Model (DEM) The high-resolution DEM is the basis for calculation of water connectivity, among other things. Most of the documentation of the creation of the DEM for CS10 has been lost to the sands of time. All we know is that it is located here: dem_path &lt;- &quot;model_data/input/elevation/dtm3_ns_v5.tif&quot; plot(raster(dem_path)) Figure 2.1: CS10 Digital elevation model (DEM). To our knowledge, it has a 10 meter resolution. 1 meter resolution was available but there seems to have been issues with using it. It is definitely preferable to use the 1m DEM as certain important information can be lost with (max allowed resolution) of 10m. An example of a hydrologically effective landscape features being lost due to coarse DEM resolution. From (Schürz et al. 2022) 2.1.2 Processing the Basin Boundary The basin boundary has presumably been created using the defined outlet point of the catchment and the DEM. No more is currently known about this file other than that it is located here: bound_path &lt;- &quot;model_data/input/shape/cs10_basin.shp&quot; Figure 2.2: CS10 Basin, caclulated from the DEM. We will begin using the SWATBuildR Package by initializing its functions. (Note: this package is currently unfinished, which is why this step is necessary). The following code and commentary is from version 1.5.12, written by Christoph Schuerz. Another note: there are currently issues with White box which are being resolved. source(&#39;model_data/swat_buildR/init.R&#39;) BuildR recommends all layers to be in the same CRS, if we set project_layer to FALSE, it will throw an error when this is not the case: The input layers might be in different coordinate reference systems (CRS). It is recommended to project all layers to the same CRS and check them before using them as model inputs. The model setup process checks if the layer CRSs differ from the one of the basin boundary. By setting ‘proj_layer &lt;- TRUE’ the layer is projected if the CRS is different. If FALSE different CRS trigger an error. project_layer &lt;- TRUE We read in and check the basin boundary and run some checks bound &lt;- read_sf(bound_path) %&gt;% select() set_proj_crs(bound, data_path) check_polygon_topology(layer = bound, data_path = data_path, label = &#39;basin&#39;, n_feat = 1, checks = c(F,T,T,T,F,F,F,F)) 2.1.3 Processing the Land layer Our land layer is located here: land_path &lt;- &quot;model_data/input/land/CS10_LU.shp&quot; Documentation on its creation does not exist. Figure 2.3: Land use map of CS10 by Farm ID Land use map of CS10 by Farm ID We had an issue with the classification of the land uses. For the OPTAIN project, all agricultural fields must have a unique ID, and our land uses only had the ID of the given farm KGB (which had many different fields). To remedy this, new IDs were generated with the format a_###f_# where a_ represents the farm, and f_ represents the respective field of that farm. The farm names needed to be shortened because the SWAT+ model often cannot handle long ID names (longer than 16 characters) Note, the potential measures polygons were not counted as individual fields, which is why SP_ID does not match up with field_ID – This is by design. readr::read_csv(&quot;model_data/farm_id/a_f_id.csv&quot;, show_col_types = F) %&gt;% head() ## # A tibble: 6 × 4 ## KGB type_fr sp_id field_ID ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 213/8/1 a_084 1 a_084f_1 ## 2 213/7/6 a_083 2 a_083f_1 ## 3 213/7/6 a_083 3 a_083f_2 ## 4 213/7/4 a_082 4 a_082f_1 ## 5 213/65/1 a_081 5 a_081f_1 ## 6 213/65/1 a_081 6 a_081f_2 This was done in a simple QGIS workflow of dissolving by farm, splitting from single part to multipart, and then adding an iterating ID per farm field. This workflow could be replicated in R, and then shown here. It is under consideration… BuildR will now run some checks on our land layer. land &lt;- read_sf(land_path) %&gt;% check_layer_attributes(., type_to_lower = FALSE) %&gt;% check_project_crs(layer = ., data_path = data_path, proj_layer = project_layer, label = &#39;land&#39;, type = &#39;vector&#39;) check_polygon_topology(layer = land, data_path = data_path, label = &#39;land&#39;, area_fct = 0.00, cvrg_frc = 99.9, checks = c(T,F,T,T,T,T,T,T)) BuildR splits the land layer into HRU (land) and reservoir (water) objects split_land_layer(data_path) 2.1.4 Processing the Channels No documentation exists on the source of the channels layer, all we know is that it is located here: channel_path &lt;- &#39;model_data/input/line/cs10_channels.shp&#39; channels &lt;- read_sf(channel_path) %&gt;% dplyr::select(&quot;type&quot;) channel_map &lt;- ggplot()+geom_sf(data= bound_sf)+geom_sf(data = channels, mapping = aes(color = type))+sf_theme channel_map (#fig:channel_plot)CS10 Channels, including surface (cha) and subsurface channels (sub) BuildR runs some checks: channel &lt;- read_sf(channel_path) %&gt;% check_layer_attributes(., type_to_lower = TRUE) %&gt;% check_project_crs(layer = ., data_path = data_path, proj_layer = project_layer, label = &#39;channel&#39;, type = &#39;vector&#39;) check_line_topology(layer = channel, data_path = data_path, label = &#39;channel&#39;, length_fct = 0, can_cross = FALSE) BuildR then checks the connectivity between the channels and reservoirs. For this we need to define our id_cha_out and id_res_out. Variable id_cha_out sets the outlet point of the catchment. Either define a channel OR a reservoir as the final outlet. If channel then assign id_cha_out with the respective id from the channel layer. If reservoir then assign the respective id from the land layer to id_res_out, otherwise leave as NULL id_cha_out &lt;- 37 id_res_out &lt;- NULL Running connectivity checks between channels and reservoirs: check_cha_res_connectivity(data_path, id_cha_out, id_res_out) Checking if any defined channel ids for drainage from land objects do not exist check_land_drain_ids(data_path) 2.1.5 Processing the DEM BuildR loads and checks the DEM, and saves it. dem &lt;- rast(dem_path) %&gt;% check_project_crs(layer = ., data_path = data_path, proj_layer = project_layer, label = &#39;dem&#39;, type = &#39;raster&#39;) check_raster_coverage(rst = dem, vct_layer = &#39;land&#39;, data_path = data_path, label = &#39;dem&#39;, cov_frc = 0.95) save_dem_slope_raster(dem, data_path) 2.1.6 Processing soil data Our soil map is located here: soil_layer_path &lt;- &#39;model_data/input/soil/soil_layer.tif&#39; No documentation exists on its creation. Figure 2.4: CS10 Soil map The soil data and look-up path are located here: soil_lookup_path &lt;- &#39;model_data/input/soil/soil_lookup.csv&#39; soil_data_path &lt;- &#39;model_data/input/soil/UserSoil_Krakstad.csv&#39; Not much documentation exists here either. Some can be found in the excel sheet: ## [1] &quot;model_data/input/soil/swatsoil2.xlsx&quot; BuildR reads in the soil data, performs checks, processes, and saves. NOTE: THIS IS CURRENTLY BROKEN, WITH ERROR MESSAGE: Warning: Cannot find coordinate operations from EPSG:2583 [“unnamed”,EDATUM[“”], CS[Cartesian,2], AXIS[“(E)”, east, ORDER[1], LENGTHUNIT[“unknown”, 1]], AXIS[“(N)”, north, ORDER[2], LENGTHUNIT[“unknown”, 1]]]’ (GDAL error 6) Error: [project] Cannot do this transformation soil &lt;- rast(soil_layer_path) %&gt;% check_project_crs(layer = ., data_path = data_path, proj_layer = project_layer, label = &#39;soil&#39;, type = &#39;raster&#39;) check_raster_coverage(rst = soil, vct_layer = &#39;hru&#39;, data_path = data_path, label = &#39;soil&#39;, cov_frc = 0.75) # BROKEN #save_soil_raster(soil, data_path) # added soil.tif from back when it used to work BuildR then generates a table with aggregated elevation, slope, soil for HRU units. # waiting on soil fix. #aggregate_hru_dem_soil(data_path) Read and prepare the soil input tables and a soil/hru id table and write them into data_path/tables.sqlite #build_soil_data(soil_lookup_path, soil_data_path, data_path) 2.2 Calculating Contiguous Object Connectivity SWATBuildR follows COCOA. This section contains the calculations. You can read more about it in the protocol (ref). 2.2.1 Calculating land unit connectivity Preparing raster layers based on the DEM and the surface channel objects that will be used in the calculation of the land object connectivity. #prepare_terrain_land(data_path) The connection of each land object to neighboring land and water objects is calculated based on the flow accumulation and the D8 flow pointer along the object edge # calculate_land_connectivity(data_path) 2.2.1.1 Eliminate land object connections with small flow fractions: For each land object the flow fractions are compared to connection with the largest flow fraction of that land object. Connections are removed if their fraction is smaller than frc_thres relative to the largest one. This is necessary to: Simplify the connectivity network To reduce the risk of circuit routing between land objects. Circuit routing will be checked. If an error due to circuit routing is triggered, then ‘frc_thres’ must be increased to remove connectivities that may cause this issue. frc_thres &lt;- 0.3 The remaining land object connections are analyzed for infinite loop routing. For each land unit the connections are propagated and checked if the end up again in the same unit. #reduce_land_connections(data_path, frc_thres) %&gt;% # check_infinite_loops(., data_path, &#39;Land&#39;) If infinite loops were identified this routine tries to resolve the issues by selectively removing connections between land units in order to get rid of all infinite loops. # resolve_loop_issues(data_path) 2.2.2 Calculating channel/reservoir connectivity 2.2.2.1 Calculating the water object connectivity the function returns the cha and res con_out tables in SWAT+ database format and writes them into data_path/tables.sqlite #build_water_object_connectivity(data_path) 2.2.3 Checking the water objects for infinite loops From the cha_res_con_out tables id_from/id_to links are generated and checked for infinite loop routing. #prepare_water_links(data_path) %&gt;% # check_infinite_loops(., data_path, &#39;Water&#39;, Inf) 2.2.4 Terrain properties Calculate terrain properties such as elevation, slope, catchment area, channel width/depth for channel and reservoir objects and write them into data_path/tables.sqlite #prepare_terrain_water(data_path) 2.3 Generate SWAT+ input 2.3.1 Generate land object SWAT+ input tables Build the landuse.lum and a landuse/hru id table and write them into data_path/tables.sqlite #build_landuse(data_path) Build the HRU SWAT+ input files and write them into data_path/tables.sqlite #build_hru_input(data_path) Add wetlands to the HRUs and build the wetland input files and write them into data_path/tables.sqlite (TODO fix this!) wetland_landuse &lt;- c(&#39;wehb&#39;, &#39;wetf&#39;, &#39;wetl&#39;, &#39;wetn&#39;) #add_wetlands(data_path, wetland_landuse) 2.3.2 Generate water object SWAT+ input tables Build the SWAT+ cha input files and write them into data_path/tables.sqlite #build_cha_input(data_path) Build the SWAT+ res input files and write them into data_path/tables.sqlite #build_res_input(data_path) Build SWAT+ routing unit con_out based on ‘land_connect_fraction’. #build_rout_con_out(data_path) Build the SWAT+ rout_unit input files and write them into data_path/tables.sqlite #build_rout_input(data_path) Build the SWAT+ LSU input files and write them into data_path/tables.sqlite #build_ls_unit_input(data_path) 2.3.3 Build aquifer input Build the SWAT+ aquifer input files for a single aquifer for the entire catchment. The connectivity to the channels with geomorphic flow must be added after writing the txt input files. This is not implemented in the script yet. #build_single_aquifer_files(data_path) 2.4 Add point source inputs The point source locations are provided with a point vector layer in the path ‘point_path’. point_path &lt;- &#39;model_data/input/point/cs10_pointsource.shp&#39; point_sf &lt;- read_sf(point_path) point_map &lt;- mapview(point_sf, zcol = &quot;GRAD_P&quot;, cex = &quot;GRAD_N&quot;) mapview(bound_sf, alpha.regions = 0.2)+point_map Map of point sources, colored by (assumed) phosphorous and size by (assumed) Nitrogren Maximum distance of a point source to a channel or a reservoir to be included as a point source object (recall) in the model setup: max_point_dist &lt;- 500 #meters Point source records can automatically be added from files in the same folder as the point source location layer. To be identified as point source data the files must be named as &lt;name&gt;_&lt;interval&gt;.csv, where &lt;name&gt; must be the name of a point int the vector layer and &lt;interval&gt; must be one of const, yr, mon, or day depending on the time intervals in the input data. #add_point_sources(point_path, data_path, max_point_dist) 2.5 Create SWAT+ sqlite database 2.5.1 Write the SWAT+Editor project database The database will be located the ‘project_path’. After writing the database it can be opened and edited with the SWAT+Editor. #create_swatplus_database(project_path, project_name) The next step involves you entering the SWAT+ Editor and parameterizing the model from there. These are the steps we have taken, with screenshots since it is currently not possible to replicate this process in R. 2.5.2 TODO Switch to SWAT+Editor for further model parametrization and continue with the step below after writing the SWAT+ projects’ text input files 2.5.3 Link aquifers and channels with geomorphic flow A SWATbuildR model setup only has one single aquifer (in its current version). This aquifer is linked with all channels through a channel- aquifer-link file (aqu_cha.lin) in order to maintain recharge from the aquifer into the channels using the geomorphic flow option of SWAT+ The required input file cannot be written with the SWAT+Editor. Therefore it has to be generated in a step after writing the model text input files with the SWAT+Editor. Path of the TxtInOut folder (project folder where the SWAT+ text files are written with the SWAT+Editor) txt_path &lt;- &#39;../swat_runs/txtinouit/&#39; #link_aquifer_channels(txt_path) … References "],["part-model-parameterization.html", "Chapter 3 (PART) Model parameterization", " Chapter 3 (PART) Model parameterization "],["climate-inputs-and-weather-generator.html", "Chapter 4 Climate inputs and weather generator 4.1 Preperation and loading data 4.2 Creating the weather generator 4.3 Adding weather data to SWAT project", " Chapter 4 Climate inputs and weather generator 4.1 Preperation and loading data To add weather and climate data to our SWAT project, we will use svatools 4.1.1 Required packages require(euptf2) # devtools::install_github(&quot;tkdweber/euptf2&quot;) require(svatools) # devtools::install_github(&quot;biopsichas/svatools&quot;) require(readr) require(readxl) require(sf) require(mapview) 4.1.2 Load in the file(s) and load svatools template First we load in the template and fill it in with our values and rename it to “cs10_weather_data.xlsx”. This is not done within R. #temp_path &lt;- system.file(&quot;extdata&quot;, &quot;weather_data.xlsx&quot;, package = &quot;svatools&quot;) # /// fill out this template and save &quot;cs10_weather_data.xlsx&quot; /// We are using the following projection for this project: epgs_code = 25832 Now we can load it in with Svatools. met_lst &lt;- load_template(template_path = &quot;model_data/input/met/cs10_weather_data.xlsx&quot;, epgs_code) ## [1] &quot;Loading data from template.&quot; ## [1] &quot;Reading station ID1 data.&quot; ## [1] &quot;Loading of data is finished.&quot; 4.1.3 Proof the station plot_weather(met_lst, &quot;PCP&quot;, &quot;month&quot;, &quot;sum&quot;) Checking the location of the station: basin_path &lt;- &quot;model_data/input/shape/cs10_basin.shp&quot; basin &lt;- st_transform(st_read(basin_path), epgs_code) %&gt;% mutate(NAME = &quot;Basin&quot;) ## Reading layer `cs10_basin&#39; from data source ## `C:\\Users\\mosh\\Documents\\GitHub\\NIBIO\\optain-cs10\\model_data\\input\\shape\\cs10_basin.shp&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 1 feature and 1 field ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: 603439.4 ymin: 6607792 xmax: 610984.4 ymax: 6622017 ## Projected CRS: ETRS89 / UTM zone 32N stations &lt;- st_transform(met_lst$stations, epgs_code) mapview(stations) + mapview(basin) 4.2 Creating the weather generator We only have one weather station, which means only one weather generator. wgn &lt;- prepare_wgn(met_lst, TMP_MAX = met_lst$data$ID1$TMP_MAX, TMP_MIN = met_lst$data$ID1$TMP_MIN, PCP = met_lst$data$ID1$PCP, RELHUM = met_lst$data$ID1$RELHUM, WNDSPD = met_lst$data$ID1$WNDSPD, MAXHHR = met_lst$data$ID1$MAXHHR, SLR = met_lst$data$ID1$SLR) ## [1] &quot;Coordinate system checked and transformed to EPSG:4326.&quot; ## [1] &quot;Working on station ID1:WS_AAS&quot; write.csv(wgn$wgn_st, &quot;model_data/input/met/as_wgn_st.csv&quot;, row.names = FALSE, quote = FALSE) write.csv(wgn$wgn_data, &quot;model_data/input/met/as_wgn_data.csv&quot;, row.names = FALSE, quote = FALSE) 4.3 Adding weather data to SWAT project Currently, this throws an error – Cannot tell why, but might not be an issue because it still writes the files that we need. Because the buildR script is currently broken, we cannot evaluate the following code db_path &lt;- &quot;model_data/cs10_setup/optain-cs10/...sqlite&quot; add_weather(db_path, met_lst, wgn) "],["crop-map-generation.html", "Chapter 5 Crop Map Generation 5.1 Calculating Farm Area 5.2 Generating the Crop Rotation 5.3 Extrapolating the Crop Rotation 5.4 Merging crop rotation with BuildR output", " Chapter 5 Crop Map Generation As OPTAIN takes into account the individual field, we need to know what is growing on which field and when. Unfortunately our data foundation for this task is quite lackluster, but we will try out best to do so. in the following chapter. require(sf) require(dplyr) require(readr) require(stringr) require(readxl) require(reshape2) require(tibble) require(DT) require(ggplot2) sf_theme &lt;- theme(axis.text.x=element_blank(), #remove x axis labels axis.ticks.x=element_blank(), #remove x axis ticks axis.text.y=element_blank(), #remove y axis labels axis.ticks.y=element_blank() #remove y axis ticks ) 5.1 Calculating Farm Area We have data based on what area certain crops have per farm. In order to relate this to our spatial land use map, we require the area of both the farms, and the fields within these farms. The basis for these calculations comes from the BuildR output: (REF header here) lu_sf &lt;- read_sf(&quot;model_data/cs10_setup/optain-cs10/data/vector/land.shp&quot;) lu_map &lt;- ggplot() + geom_sf(lu_sf, mapping = aes(fill = type)) + theme(legend.position = &quot;left&quot;) + sf_theme + theme(legend.position = &quot;none&quot;) lu_map Figure 5.1: Land use map for CS10, colored by type. 5.1.1 Calculate Field Area and Assign IDs This stage has been completed in QGIS. An R-implementation is being considered. farm_area_sf &lt;- read_sf(&quot;model_data/input/crop/buildr_output_dissolved_into_farms.shp&quot;) ggplot() + geom_sf(farm_area_sf, mapping = aes(fill = farm_id)) + theme(legend.position = &quot;none&quot;) +sf_theme Figure 5.2: Farms in the CS10 catchment, colored by ID 5.1.2 Calculate Field area and assign IDs This stage has been completed in QGIS. An R-implementation is being considered. 5.2 Generating the Crop Rotation The following algorithm takes information from reporting farm, and their respective area in the SWAT+ setup, and combines these data sets to generate a plausible crop rotation. Note, pasture refers to meadow (TODO: fix!) crop_data &lt;- read_excel(&quot;model_data/input/crop/crop_rotation_source_data.xlsx&quot;) datatable(crop_data) 5.2.1 Tidy up the source data: We are converting the source data to tidy format in the following code snippet crop_names &lt;- melt( crop_data, id.vars = c(&quot;farm_id&quot;, &quot;year&quot;, &quot;area_daa&quot;, &quot;pastrure_area_daa&quot;), measure.vars = c(&quot;crop1&quot;, &quot;crop2&quot;, &quot;crop3&quot;), variable.name = &quot;crop_status&quot;, value.name = &quot;crop&quot; ) %&gt;% tibble() crop_area &lt;- melt( crop_data, id.vars = c(&quot;farm_id&quot;, &quot;year&quot;, &quot;area_daa&quot;, &quot;pastrure_area_daa&quot;), measure.vars = c(&quot;percent_crop1&quot;, &quot;percent_crop2&quot;, &quot;percent_crop3&quot;), variable.name = &quot;crop_status&quot;, value.name = &quot;area&quot; ) %&gt;% tibble() crop_area$crop_status &lt;- crop_area$crop_status %&gt;% str_remove(&quot;percent_&quot;) # unstable, TODO fix! colnames(crop_area)[6] &lt;- &quot;crop_area_percent&quot; crop_tidy &lt;- left_join(crop_names, crop_area, by = c(&quot;farm_id&quot;, &quot;year&quot;, &quot;area_daa&quot;,&quot;pastrure_area_daa&quot;, &quot;crop_status&quot;)) %&gt;% dplyr::select(-crop_status) # unstable, TODO fix! colnames(crop_tidy)[3] &lt;- &quot;farm_area_daa&quot; crop_tidy$crop_area_percent &lt;- (crop_tidy$crop_area_percent/100) %&gt;% round(2) crop_tidy &lt;- crop_tidy %&gt;% filter(crop %&gt;% is.na() == FALSE) datatable(crop_tidy) 5.2.2 Tidy up the BuildR output The maps shown in secttion (ref) were exported to CSV in QGIS. An R-implementation might be written in here sometime (#TODO). This CSV data needs to be re-formatted to be tidy as well. fields &lt;- read_csv( &quot;model_data/input/crop/buildr_landuse_dissolved_into_fields.csv&quot;, show_col_types = F ) %&gt;% dplyr::select(type, farm_id, field_area_daa) farms &lt;- read_csv( &quot;model_data/input/crop/buildr_landuse_dissolved_into_farms.csv&quot;, show_col_types = F ) %&gt;% dplyr::select(type, farm_id , farm_area_) # fix farm_area_ # unstable, fix! colnames(farms)[3] &lt;- &quot;farm_area_daa&quot; farms$farm_area_daa &lt;- farms$farm_area_daa %&gt;% round(2) fields$field_area_daa &lt;- fields$field_area_daa %&gt;% round(2) reported_data &lt;- left_join(fields, farms, by = &quot;farm_id&quot;) # unstable, fix! colnames(reported_data)[1] &lt;- &quot;field_id&quot; reported_data &lt;- reported_data %&gt;% dplyr::select(field_id, farm_id, field_area_daa, farm_area_daa) datatable(reported_data) 5.2.3 Field classification We are now ready to perform our classification. We will store our results in this predefined dataframe: classed_fields &lt;- tibble( farm_id = NA, field_id = NA, farm_area_daa = NA, field_area_daa = NA, crop = NA, year = NA ) The following reporting farms will be used for the classification: farms &lt;- reported_data$farm_id %&gt;% unique() For the following years (AKA we have data for these years): years &lt;- c(2016, 2017, 2018, 2019) This for loop runs through all the fields and classifies them. The output will not be printed in this file, but will be saved in a log file, that you can dig out of the repository, located here: #TODO add the log file generation The following code is not executed: # For every year for(c_year in years){ # For every farm, for (farm in farms) { # Do the following: # Filter the source and buildR data to the given year and farm crop_filter &lt;- crop_tidy %&gt;% filter(year == c_year) %&gt;% filter(farm_id == farm) hru_filter &lt;- reported_data %&gt;% filter(farm_id == farm) # Behavior if the farm has no reporting data: if(crop_filter$farm_id %&gt;% length() == 0){ # Set all fields to winter wheat. farm_fields &lt;- hru_filter %&gt;% dplyr::select(farm_id, field_id, farm_area_daa, field_area_daa) %&gt;% arrange(desc(field_area_daa)) farm_fields$crop = &quot;wwht&quot; farm_fields$year = c_year # Add them to the results dataframe classed_fields &lt;- rbind(classed_fields, farm_fields) # and skipping to next farm next() } # Behavior, if there is reporting data on the farm&quot; # Find the area of the farm (all elements in vector are the same, so ok # to just grab the first) farm_area_hru &lt;- hru_filter$farm_area_daa[1] # Find the discrepency between &quot;SHOULD BE&quot; crop area and &quot;CURRENTLY IS&quot; # crop area. We want this as an absolute value. area_dis &lt;- (hru_filter$farm_area_daa[1]-crop_filter$farm_area_daa[1]) %&gt;% round(2) %&gt;% abs() # Some farms have no reported area. in this case we set it to some random # negative number. if(area_dis %&gt;% is.na()){area_dis = -999} # Extracting the area of the pasture and farm (all vectors same value, ok # to just take the first) past_area &lt;- crop_filter$pastrure_area_daa[1] farm_area &lt;- crop_filter$farm_area_daa[1] # Extract relevant fields farm_fields &lt;- hru_filter %&gt;% dplyr::select(farm_id, field_id, farm_area_daa, field_area_daa) %&gt;% # and sort by area arrange(desc(field_area_daa)) # pre-define crops column to be NA farm_fields$crop = NA # Bollean check to see if the field has been meadow in a previous year. If # it has, then we want to continue planting meadow on it (This was a # decision we made.) has_meadow &lt;- (classed_fields %&gt;% filter(field_id %in% farm_fields$field_id) %&gt;% filter(crop == &quot;meadow&quot;) %&gt;% dplyr::select(field_id) %&gt;% pull() %&gt;% length() &gt; 0) ### Determining how much land the crops should cover. # This if statement checks if is currently a pasture portion for the reporting # farm, or if there has been in the past. if((past_area %&gt;% is.na() == FALSE) | has_meadow) { # If it does, or did, then this special routine is enacted: # Determines the pasture percentage of the total farm past_percent &lt;- (past_area/farm_area) # If it cannot be calculated, then it is set to 0 if(past_percent %&gt;% is.na()){past_percent = 0} # The crop fractions provided to us in the source data did not account for # the pasture fraction. therefore we need to reduce the other crop # fractions by this amount. adjuster &lt;- past_percent / length(crop_filter$crop) crop_filter$crop_area_percent &lt;- crop_filter$crop_area_percent-adjuster # creating a new entry for pasture and adding it to the now updated crop\\ # fractions list past_row &lt;- tibble( farm_id = farm, year = c_year, farm_area_daa = crop_filter$farm_area_daa[1], pastrure_area_daa = past_area, crop = &quot;meadow&quot;, crop_area_percent = past_percent ) crop_filter &lt;- rbind(crop_filter, past_row) # Creating an updated &quot;SHOULD BE&quot; and &quot;CURRENTLY IS&quot; crop coverage # datafram crop_coverage &lt;- tibble( crop = crop_filter$crop, to_cover = (farm_area_hru*crop_filter$crop_area_percent)) # Setting the initial actual coverage to 0 (&quot;CURRENTLY IS&quot;) crop_coverage$actual &lt;- 0 # This extracts the fields that were previously pasture fields. previously_pasture &lt;- classed_fields %&gt;% filter(field_id %in% farm_fields$field_id) %&gt;% filter(crop == &quot;meadow&quot;) %&gt;% dplyr::select(field_id) %&gt;% pull() if (length(previously_pasture) &gt; 0) { # if some of the fields were previously pasture, they are set to pasture # again: farm_fields$crop[ which(farm_fields$field_id %in% previously_pasture)] = &quot;meadow&quot; # We save the amount of area the meadow crops cover, so that we can # adjust the other &quot;SHOULD BE&quot; fractions correctly. custom_actual &lt;- farm_fields %&gt;% filter(crop == &quot;meadow&quot;) %&gt;% dplyr::select(field_area_daa) %&gt;% pull() %&gt;% sum(na.rm = T) crop_coverage$actual[which(crop_coverage$crop==&quot;meadow&quot;)] = custom_actual } # Now the algorithm continues as normal. # This is the routine that is run, when no meadow is detected: }else{ # creating a tibble which tracks how much land the crops SHOULD cover crop_coverage &lt;- tibble( crop = crop_filter$crop, to_cover = (farm_area_hru * crop_filter$crop_area_percent) ) # pre define crop coverage to 0 (CURRENT) crop_coverage$actual &lt;- 0 } ### Crop classification # Now we know how much land the crops SHOULD cover, it is time to assign # the fields accordingly. We do this with a WHILE loop, which keeps going # until we have classified every field. while(any(farm_fields$crop %&gt;% is.na())){ # run through all the crops in the crop coverage list and determine or # update their current coverage for (c_crop in crop_coverage$crop) { # figure out which index we are in the list crop_index &lt;- which(c_crop == crop_coverage$crop) # Determine/UPDATE the current actual coverage of the crop (sum) crop_coverage$actual[crop_index] &lt;- farm_fields %&gt;% filter(crop == c_crop) %&gt;% dplyr::select(field_area_daa) %&gt;% sum() } # Calculate the difference between crop SHOULD BE coverage and ACTUAL # coverage crop_coverage$diff &lt;- crop_coverage$actual-crop_coverage$to_cover # determine the maximum difference. max_diff &lt;- crop_coverage$diff %&gt;% min(na.rm = T) # determine which crop has the maximum difference max_diff_crop &lt;- crop_coverage$crop[which(crop_coverage$diff == max_diff) %&gt;% min(na.rm = T)] # determine the biggest field left un-classified. biggest_na_field &lt;- farm_fields %&gt;% filter(crop %&gt;% is.na()) %&gt;% arrange(desc(field_area_daa)) %&gt;% nth(1) # Set the field which is still NA, and also the biggest to the crop with # the maximum difference (This code seems weird, and could be # improved?) farm_fields$crop[which((farm_fields$crop %&gt;% is.na() == TRUE) &amp; farm_fields$field_area_daa == biggest_na_field$field_area_daa )] &lt;- max_diff_crop } # After having classified the field, we update the actual coverage value # the respective crop that has been classified. for (c_crop in crop_coverage$crop) { crop_index &lt;- which(c_crop == crop_coverage$crop) crop_coverage$actual[crop_index] &lt;- farm_fields %&gt;% filter(crop == c_crop) %&gt;% dplyr::select(field_area_daa) %&gt;% sum() } # save the year of this crop assignment in the dataframe farm_fields$year = c_year # add the classification to the result dataframe classed_fields &lt;- rbind(classed_fields, farm_fields) # and move onto the next farm } # for every year } # Remove the first NA line classed_fields &lt;- classed_fields[-1, ] Now we can have a look at our results (not evaluated) datatable(classed_fields) We can now extract the crop rotation from this datatable. (not evaluated) # the format of our final dataframe final_df &lt;- tibble(field = NA, y_2016 = NA, y_2017 = NA, y_2018 = NA, y_2019 = NA) # fields we need to extract field_ids &lt;- classed_fields$field_id %&gt;% unique() We will do this with this for loop (note this is bad R-practice. Should be done with something like pivot_longer (TODO)) for(c_field_id in field_ids) { crop_rotation &lt;- tibble(field = c_field_id) crops &lt;- classed_fields %&gt;% filter(field_id == c_field_id) %&gt;% dplyr::select(crop) %&gt;% t() %&gt;% as_tibble(.name_repair = &quot;minimal&quot;) colnames(crops) &lt;- c(&quot;y_2016&quot;, &quot;y_2017&quot;, &quot;y_2018&quot;, &quot;y_2019&quot;) crop_rotation &lt;- cbind(crop_rotation, crops) %&gt;% as_tibble() final_df &lt;- rbind(final_df, crop_rotation) } # Remove the first NA line crop_rotation &lt;- final_df[-1,] # Save the crop rotation in CSV format write_csv(x = crop_rotation, file = &quot;model_data/input/crop/cs10_crop_rotation.csv&quot;) Here is a look at the crop rotation: The crop rotation looks like this: ## Loading required package: gifski (#fig:cro_gif)Generated crop rotation for CS10. 5.3 Extrapolating the Crop Rotation For OPTAIN, the crop rotation needs to span from 1988 to 2020. We currently have 2016 to 2019. crop_rotation &lt;- read_csv(&quot;model_data/input/crop/cs10_crop_rotation.csv&quot;, show_col_types = F) rotation &lt;- crop_rotation %&gt;% dplyr::select(-field) crop_rotation_extrapolated &lt;- cbind(crop_rotation, rotation, rotation, rotation, rotation, rotation, rotation, rotation, rotation$y_2016) # set the column names to be in the correct format colnames(crop_rotation_extrapolated) &lt;- c(&quot;field&quot;, paste0(&quot;y_&quot;, 1988:2020)) 5.4 Merging crop rotation with BuildR output The output of SWATbuildR “land.shp” needs to be connected to the newly generated crop map. lu &lt;- read_sf(&quot;model_data/cs10_setup/optain-cs10/data/vector/land.shp&quot;) # temporary rename to field, for the left join # unstable, fix! colnames(lu)[2] = &quot;field&quot; # join the crop rotation and land use layer by their field ID lu_cr &lt;- left_join(lu, crop_rotation_extrapolated, by = &quot;field&quot; ) # reset column name. # unstable, fix! colnames(lu_cr)[2] = &quot;lu&quot; # Write the new shape file write_sf(lu_cr, &quot;model_data/input/crop/land_with_cr.shp&quot;) "],["landuse.lum-update.html", "Chapter 6 Landuse.lum update 6.1 Data preperation 6.2 Assigning landuse values 6.3 Writing Changes", " Chapter 6 Landuse.lum update This section covers the modifications made to the landuse file. For some reason it was written in a tutorial fashion, as if the reader were new to R. require(tidyverse) require(reshape2) require(sf) require(DT) require(dplyr) # require dplyr last to overwrite plyr count() require(ggplot2) ggplot theme(s): sf_theme &lt;- theme(axis.text.x=element_blank(), #remove x axis labels axis.ticks.x=element_blank(), #remove x axis ticks axis.text.y=element_blank(), #remove y axis labels axis.ticks.y=element_blank() #remove y axis ticks ) 6.1 Data preperation We read in the land use file. We want to set skip = 1 to ignore the SWAT+editor text, and set header = T. We then convert it to a tibble format for better printing to console landuse_lum &lt;- read.table(&quot;model_data/cs10_setup/temp_landuse.lum&quot;, skip = 1, header = T) %&gt;% tibble::as_tibble() (#tab:lum_tab)The landuse.lum file, post BuildR name cal_group plnt_com mgt cn2 cons_prac urban urb_ro ov_mann tile sep vfs grww bmp a_001f_1_drn_lum null nopl_comm null null null null null null mw24_1000 null null null null a_001f_2_drn_lum null nopl_comm null null null null null null mw24_1000 null null null null a_001f_3_drn_lum null nopl_comm null null null null null null mw24_1000 null null null null a_001f_4_drn_lum null nopl_comm null null null null null null mw24_1000 null null null null a_001f_5_drn_lum null nopl_comm null null null null null null mw24_1000 null null null null a_001f_6_drn_lum null nopl_comm null null null null null null mw24_1000 null null null null a_001f_7_drn_lum null nopl_comm null null null null null null mw24_1000 null null null null a_002f_1_drn_lum null nopl_comm null null null null null null mw24_1000 null null null null a_002f_2_drn_lum null nopl_comm null null null null null null mw24_1000 null null null null a_002f_3_drn_lum null nopl_comm null null null null null null mw24_1000 null null null null Our field_id for our cropland does not match name of landuse_lum so we need to parse it out, we can do this many ways, but a safe way is to split it by “_” and combine the first 3 splits with that same underscore: splitted &lt;- landuse_lum$name %&gt;% str_split(&quot;_&quot;) landuse_lum$field_id &lt;- paste(splitted %&gt;% map(1), splitted %&gt;% map(2), splitted %&gt;% map(3), sep = &quot;_&quot;) head(landuse_lum$field_id) ## [1] &quot;a_001f_1&quot; &quot;a_001f_2&quot; &quot;a_001f_3&quot; &quot;a_001f_4&quot; &quot;a_001f_5&quot; &quot;a_001f_6&quot; But wait, this does not work for our “non-fields”. So lets find out which ones they are, and set them to NA not_fields &lt;- which(!grepl(x=landuse_lum$field_id, &quot;a_&quot;)) landuse_lum$field_id[not_fields] &lt;- NA So, what non-fields do we have? landuse_lum$name[not_fields] ## [1] &quot;frst_lum&quot; &quot;past_lum&quot; &quot;rngb_lum&quot; &quot;urml_lum&quot; &quot;utrn_lum&quot; &quot;wetf_lum&quot; Good to know. We’ll keep that in mind. 6.2 Assigning landuse values 6.2.1 Setting cal_group There is no info on this column, so we are going to leave it as null. 6.2.2 Setting plnt_com This step will be done by SWATFarmR 7. 6.2.3 Setting mgt This step will be done by SWATFarmR 7. 6.2.4 Setting urb_ro We want to set the urb_ro column for all urban land uses (in our case this would be urml and utrn) to usgs_reg. We can do this like so: landuse_lum$urb_ro[which(landuse_lum$name %in% c(&quot;urml_lum&quot;, &quot;utrn_lum&quot;))] &lt;- &quot;usgs_reg&quot; (#tab:urbro_tab)Changing urb_ro in the landuse file name cal_group plnt_com mgt cn2 cons_prac urban urb_ro ov_mann tile sep vfs grww bmp field_id urml_lum null null null null null null usgs_reg null null null null null null NA utrn_lum null null null null null null usgs_reg null null null null null null NA Very good. In our case this was only two – could be done by hand, but that will not be the case for all of our land uses. 6.2.5 Setting urban This one is easy, we set our urban column to an urban parameter set of the same name. The rest we leave as null landuse_lum$urban[which(landuse_lum$name ==&quot;utrn_lum&quot;)] &lt;- &quot;utrn&quot; landuse_lum$urban[which(landuse_lum$name ==&quot;urml_lum&quot;)] &lt;- &quot;urml&quot; (#tab:urbro_tab2)Changing urban in the landuse file name cal_group plnt_com mgt cn2 cons_prac urban urb_ro ov_mann tile sep vfs grww bmp field_id urml_lum null null null null null urml usgs_reg null null null null null null NA Lets make sure other land uses still have null: Table 6.1: Landuse frst in the landuse file name cal_group plnt_com mgt cn2 cons_prac urban urb_ro ov_mann tile sep vfs grww bmp field_id frst_lum null nopl_comm null null null null null null null null null null null NA Looks good. 6.2.6 Setting Manning’s n (ovn) Lets get the easy ones out of the way landuse_lum$ov_mann[which(landuse_lum$name ==&quot;past_lum&quot;)] &lt;- &quot;densegrass&quot; landuse_lum$ov_mann[which(landuse_lum$name ==&quot;rngb_lum&quot;)] &lt;- &quot;rangeland_20cover&quot; landuse_lum$ov_mann[which(landuse_lum$name ==&quot;urml_lum&quot;)] &lt;- &quot;urban_rubble&quot; landuse_lum$ov_mann[which(landuse_lum$name ==&quot;urtn_lum&quot;)] &lt;- &quot;urban_asphalt&quot; Don’t fall asleep yet! For wetf we want forest_heavy but with a higher value. this means we need to add a new entry. And since we are doing this fancy Rmarkdown stuff, we’re going to do it with code! Lets jump in and get at this file. (REMEBER TO REMOVE THE TEMP) ovn_table_path &lt;- &quot;model_data/cs10_setup/temp_ovn_table.lum&quot; ovn_table &lt;- readLines(ovn_table_path) Good, now where is this forest heavy entry? and what does the format look like? index &lt;- grepl(x=ovn_table, &quot;forest_heavy&quot;) %&gt;% which %&gt;% min() ovn_table[c(2, index)] %&gt;% print() ## [1] &quot;name ovn_mean ovn_min ovn_max description&quot; ## [2] &quot;forest_heavy 0.80000 0.70000 0.90000 Forest_heavy&quot; Now, lets make our own and add it in. But only if it doesn’t exist it (Like if the script has been run before…) if(grepl(x = ovn_table, &quot;forest_heavy_cs10&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;forest_heavy_cs10 0.90000 0.80000 0.95000 Forest_heavy_mod&quot; ovn_table &lt;- c(ovn_table, entry) } Did it work? Yes: ovn_table %&gt;% tail() ## [1] &quot;forest_med 0.60000 0.50000 0.70000 Forest_medimum_good&quot; ## [2] &quot;forest_heavy 0.80000 0.70000 0.90000 Forest_heavy&quot; ## [3] &quot;urban_asphalt 0.01100 0.01100 0.01100 Urban_asphalt&quot; ## [4] &quot;urban_concrete 0.01200 0.01200 0.01200 Urban_concrete&quot; ## [5] &quot;urban_rubble 0.02400 0.02400 0.02400 Urban_rubble&quot; ## [6] &quot;forest_heavy_cs10 0.90000 0.80000 0.95000 Forest_heavy_mod&quot; Now lets write this new table writeLines(ovn_table, con = ovn_table_path) And now we can enter our wetland class: landuse_lum$ov_mann[which(landuse_lum$name ==&quot;wetf_lum&quot;)] &lt;- &quot;forest_heavy_cs10&quot; For the fields we are going to need the crop rotation info which we created in section 5. crop_rotation &lt;- read_csv(&quot;model_data/input/crop/cs10_crop_rotation.csv&quot;, show_col_types = F) head(crop_rotation) ## # A tibble: 6 × 5 ## field y_2016 y_2017 y_2018 y_2019 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a_025f_1 wwht wwht wwht wwht ## 2 a_025f_3 wwht wwht wwht wwht ## 3 a_025f_4 wwht wwht wwht wwht ## 4 a_025f_2 wwht wwht wwht wwht ## 5 a_105f_1 wwht wwht wwht wwht ## 6 a_105f_4 wwht wwht wwht wwht We have decided to classify ovn based on the degree to which a crop rotation contains meadow, conventional crops (wwht, pota), and conservation crops (all others). To do this we need to analyze the crop rotation. Now it gets a little complicated, but trust me its not actually as bad as it looks. We need to count how many times certain crops show up in the crop rotation of a certain field. Lets do it for conventional crops first. Now, lets get into it conv_crop_count &lt;- crop_rotation %&gt;% melt(. ,&quot;field&quot;) %&gt;% group_by(field) %&gt;% filter(value %in% c(&quot;wwht&quot;, &quot;pota&quot;)) %&gt;% dplyr::count() %&gt;% dplyr::rename(conv = n) head(conv_crop_count) ## # A tibble: 6 × 2 ## # Groups: field [6] ## field conv ## &lt;chr&gt; &lt;int&gt; ## 1 a_001f_1 4 ## 2 a_001f_2 4 ## 3 a_001f_3 4 ## 4 a_001f_4 4 ## 5 a_001f_5 4 ## 6 a_001f_6 4 What happened here? well we took our crop_rotation, and melted it by field using melt. This function converts the data into tidy format (Wickham 2014). This format makes it easier to apply the following operations on a field basis. What does this look like? crop_rotation %&gt;% melt(. ,&quot;field&quot;) %&gt;% arrange(field) %&gt;% head() ## field variable value ## 1 a_001f_1 y_2016 wwht ## 2 a_001f_1 y_2017 wwht ## 3 a_001f_1 y_2018 wwht ## 4 a_001f_1 y_2019 wwht ## 5 a_001f_2 y_2016 wwht ## 6 a_001f_2 y_2017 wwht melt is a function from reshape2 which is why we required it. And what does that “.” mean in there, to the left of \"field\"?? That is a code word for the object to the left of the “pipe” (in this case crop_rotation). the pipe is “%&gt;%” and passes the object to the left of it, into the function to the right of it. look it up! When arranged by field, we can see that every field gets one entry per crop per year. This is a good format to count how many times we have a certain type of crop on a field. Next we group_by the field – this means all the following operations will be done on a field basis. Then we filter our value (which is the crop name). For conventional we needed to filter in any fields with the crop \"wwht\" or \"pota\". What does this look like? crop_rotation %&gt;% melt(. ,&quot;field&quot;) %&gt;% group_by(field) %&gt;% filter(value %in% c(&quot;wwht&quot;, &quot;pota&quot;)) ## # A tibble: 1,519 × 3 ## # Groups: field [415] ## field variable value ## &lt;chr&gt; &lt;fct&gt; &lt;chr&gt; ## 1 a_025f_1 y_2016 wwht ## 2 a_025f_3 y_2016 wwht ## 3 a_025f_4 y_2016 wwht ## 4 a_025f_2 y_2016 wwht ## 5 a_105f_1 y_2016 wwht ## 6 a_105f_4 y_2016 wwht ## 7 a_105f_2 y_2016 wwht ## 8 a_105f_3 y_2016 wwht ## 9 a_187f_1 y_2016 wwht ## 10 a_206f_1 y_2016 wwht ## # ℹ 1,509 more rows Looks good. We only have crops with winter wheat and potatoes, for every year. Exactly what we need, now we just need to count() them. conv_crop_count &lt;- crop_rotation %&gt;% melt(. ,&quot;field&quot;) %&gt;% group_by(field) %&gt;% filter(value %in% c(&quot;wwht&quot;, &quot;pota&quot;)) %&gt;% dplyr::count() head(conv_crop_count) ## # A tibble: 6 × 2 ## # Groups: field [6] ## field n ## &lt;chr&gt; &lt;int&gt; ## 1 a_001f_1 4 ## 2 a_001f_2 4 ## 3 a_001f_3 4 ## 4 a_001f_4 4 ## 5 a_001f_5 4 ## 6 a_001f_6 4 And we are back where we started! See, not that complicated. One last thing we need to do is rename n to conv, we do that like so: conv_crop_count &lt;- crop_rotation %&gt;% melt(. ,&quot;field&quot;) %&gt;% group_by(field) %&gt;% filter(value %in% c(&quot;wwht&quot;, &quot;pota&quot;)) %&gt;% dplyr::count() %&gt;% dplyr::rename(conv = n) head(conv_crop_count) ## # A tibble: 6 × 2 ## # Groups: field [6] ## field conv ## &lt;chr&gt; &lt;int&gt; ## 1 a_001f_1 4 ## 2 a_001f_2 4 ## 3 a_001f_3 4 ## 4 a_001f_4 4 ## 5 a_001f_5 4 ## 6 a_001f_6 4 Now lets go ahead and do the same thing for the two other categories: cons andmeadow. meadow_crop_count &lt;- crop_rotation %&gt;% melt(. ,&quot;field&quot;) %&gt;% group_by(field) %&gt;% filter(value == &quot;meadow&quot; ) %&gt;% dplyr::count() %&gt;% dplyr::rename(meadow = n) cons_crop_count &lt;- crop_rotation %&gt;% melt(. ,&quot;field&quot;) %&gt;% group_by(field) %&gt;% filter(!(value %in% c(&quot;wwht&quot;, &quot;pota&quot;, &quot;meadow&quot;))) %&gt;% dplyr::count() %&gt;% dplyr::rename(cons = n) cons_crop_count %&gt;% head() ## # A tibble: 6 × 2 ## # Groups: field [6] ## field cons ## &lt;chr&gt; &lt;int&gt; ## 1 a_002f_1 2 ## 2 a_002f_2 2 ## 3 a_002f_3 4 ## 4 a_002f_4 4 ## 5 a_002f_5 2 ## 6 a_002f_6 4 meadow_crop_count %&gt;% head() ## # A tibble: 6 × 2 ## # Groups: field [6] ## field meadow ## &lt;chr&gt; &lt;int&gt; ## 1 a_012f_3 4 ## 2 a_012f_6 4 ## 3 a_016f_3 4 ## 4 a_017f_2 4 ## 5 a_017f_3 4 ## 6 a_046f_1 4 meadow was a simple filter, all we have to do was grab crops with the meadow name. For cons crops, we just grabbed the remaining crops that were not conv or meadow. Great. We have these 3 separate, we need to combine them. we can do that with left_join and join by the field column which contains our IDs # create a base dataframe to join to crop_fractions &lt;- crop_rotation %&gt;% dplyr::select(field) %&gt;% distinct() # join our 3 data frames crop_fractions &lt;- left_join(crop_fractions, conv_crop_count, by = &quot;field&quot;) crop_fractions &lt;- left_join(crop_fractions, cons_crop_count, by = &quot;field&quot;) crop_fractions &lt;- left_join(crop_fractions, meadow_crop_count, by = &quot;field&quot;) # lets have a look crop_fractions %&gt;% head() ## # A tibble: 6 × 4 ## field conv cons meadow ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 a_025f_1 4 NA NA ## 2 a_025f_3 4 NA NA ## 3 a_025f_4 4 NA NA ## 4 a_025f_2 4 NA NA ## 5 a_105f_1 4 NA NA ## 6 a_105f_4 4 NA NA That does not look good! when it seems like when the count is 0, it is returned as NA. Lets fix that… crop_fractions &lt;- crop_fractions %&gt;% mutate(cons = ifelse(is.na(cons), 0, cons)) crop_fractions &lt;- crop_fractions %&gt;% mutate(conv = ifelse(is.na(conv), 0, conv)) crop_fractions &lt;- crop_fractions %&gt;% mutate(meadow = ifelse(is.na(meadow), 0, meadow)) What are we doing here? we are mutating the the 3 columns using an ifelse statement. The statement is simple. If the value is.na then we set it to 0. Otherwise, we set it to the same value it had before. did it work? crop_fractions %&gt;% head() ## # A tibble: 6 × 4 ## field conv cons meadow ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 a_025f_1 4 0 0 ## 2 a_025f_3 4 0 0 ## 3 a_025f_4 4 0 0 ## 4 a_025f_2 4 0 0 ## 5 a_105f_1 4 0 0 ## 6 a_105f_4 4 0 0 Very good. Now we need to decide what to classify our fields at. lets Define some functions to do that. is_meadow &lt;- function(conv, cons, meadow) { ((meadow &gt; cons) &amp; (meadow &gt; conv)) %&gt;% return() } is_cons &lt;- function(conv, cons, meadow) { ((cons &gt;= meadow) &amp; (cons &gt; conv)) %&gt;% return() } is_conv &lt;- function(conv, cons, meadow) { ((conv &gt;= meadow) &amp; (conv &gt;= cons)) %&gt;% return() } The &amp; sign means that both conditions need to be met. and &gt;= you should know already. Lets use those functions in action. lets do the meadow first. We will create a new dataframe from crop fractions, named field_class. field_class &lt;- crop_fractions %&gt;% mutate(meadow = is_meadow(conv,cons,meadow)) head(field_class) ## # A tibble: 6 × 4 ## field conv cons meadow ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; ## 1 a_025f_1 4 0 FALSE ## 2 a_025f_3 4 0 FALSE ## 3 a_025f_4 4 0 FALSE ## 4 a_025f_2 4 0 FALSE ## 5 a_105f_1 4 0 FALSE ## 6 a_105f_4 4 0 FALSE Ok, so none of those first 6 fields are meadow dominated. What about cons? (lets stick with our field_class dataframe and just keep adding on) field_class &lt;- field_class %&gt;% mutate(cons = is_cons(conv,cons,meadow)) head(field_class) ## # A tibble: 6 × 4 ## field conv cons meadow ## &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;lgl&gt; ## 1 a_025f_1 4 FALSE FALSE ## 2 a_025f_3 4 FALSE FALSE ## 3 a_025f_4 4 FALSE FALSE ## 4 a_025f_2 4 FALSE FALSE ## 5 a_105f_1 4 FALSE FALSE ## 6 a_105f_4 4 FALSE FALSE Nope, not cons either. Then it must be conv dominant. field_class &lt;- field_class %&gt;% mutate(conv = is_conv(conv,cons,meadow)) field_class %&gt;% head() ## # A tibble: 6 × 4 ## field conv cons meadow ## &lt;chr&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt; ## 1 a_025f_1 TRUE FALSE FALSE ## 2 a_025f_3 TRUE FALSE FALSE ## 3 a_025f_4 TRUE FALSE FALSE ## 4 a_025f_2 TRUE FALSE FALSE ## 5 a_105f_1 TRUE FALSE FALSE ## 6 a_105f_4 TRUE FALSE FALSE Correct! now lets just double check that we didnt have any cases where all are TRUE or where all are FALSE field_class %&gt;% dplyr::select(conv, cons, meadow) %&gt;% isTRUE %&gt;% all() ## [1] FALSE field_class %&gt;% dplyr::select(conv, cons, meadow) %&gt;% isFALSE() %&gt;% all() ## [1] FALSE Looks good to me! carry on: We have our field classifications now, they will be very useful to us later. Lets pull them out of our dataframe to store them as a nice list. cons_fields &lt;- field_class %&gt;% filter(cons) %&gt;% dplyr::select(field) %&gt;% pull() conv_fields &lt;- field_class %&gt;% filter(conv) %&gt;% dplyr::select(field) %&gt;% pull() meadow_fields &lt;- field_class %&gt;% filter(meadow) %&gt;% dplyr::select(field) %&gt;% pull() cons_fields %&gt;% head() ## [1] &quot;a_182f_1&quot; &quot;a_182f_5&quot; &quot;a_182f_3&quot; &quot;a_182f_4&quot; &quot;a_182f_2&quot; &quot;a_182f_7&quot; conv_fields %&gt;% head() ## [1] &quot;a_025f_1&quot; &quot;a_025f_3&quot; &quot;a_025f_4&quot; &quot;a_025f_2&quot; &quot;a_105f_1&quot; &quot;a_105f_4&quot; meadow_fields %&gt;% head() ## [1] &quot;a_182f_6&quot; &quot;a_182f_8&quot; &quot;a_017f_3&quot; &quot;a_017f_2&quot; &quot;a_012f_3&quot; &quot;a_012f_6&quot; Fantastic! Now that was a big task, but it makes the next bit very easy. Lets assign the correct ovn to the types of fields we have classified: 6.2.6.1 Agricultural Fields: Meadow landuse_lum$ov_mann[which(landuse_lum$field_id %in% meadow_fields)] &lt;- &quot;shortgrass&quot; 6.2.6.2 Agricultural Fields: Conventional landuse_lum$ov_mann[which(landuse_lum$field_id %in% conv_fields)] &lt;- &quot;convtill_nores&quot; 6.2.6.3 Agricultural Fields: Conservational landuse_lum$ov_mann[which(landuse_lum$field_id %in% cons_fields)] &lt;- &quot;falldisk_res&quot; 6.2.6.4 Forest Initially we wanted certain classes for the forest land use based on how good the soil quality was. But to do this, we would need multiple land uses, which we do not have. We will just use forest_medium for all frst. We can only change this if we go back to buildR and define more generic forest classes. landuse_lum$ov_mann[which(landuse_lum$name ==&quot;frst_lum&quot;)] &lt;- &quot;forest_med&quot; 6.2.6.5 Summary With all that data processing out of the way, lets have a quick look at what we’ve done: landuse_lum$ov_mann[which(landuse_lum$name == &quot;past_lum&quot;)] &lt;- &quot;densegrass&quot; landuse_lum$ov_mann[which(landuse_lum$name == &quot;rngb_lum&quot;)] &lt;- &quot;rangeland_20cover&quot; landuse_lum$ov_mann[which(landuse_lum$name == &quot;urml_lum&quot;)] &lt;- &quot;urban_rubble&quot; landuse_lum$ov_mann[which(landuse_lum$name == &quot;urtn_lum&quot;)] &lt;- &quot;urban_asphalt&quot; landuse_lum$ov_mann[which(landuse_lum$name == &quot;frst_lum&quot;)] &lt;- &quot;forest_med&quot; landuse_lum$ov_mann[which(landuse_lum$field_id %in% meadow_fields)] &lt;- &quot;shortgrass&quot; landuse_lum$ov_mann[which(landuse_lum$field_id %in% conv_fields)] &lt;- &quot;convtill_nores&quot; landuse_lum$ov_mann[which(landuse_lum$field_id %in% cons_fields)] &lt;- &quot;falldisk_res&quot; landuse_lum$ov_mann[which(landuse_lum$name == &quot;wetf_lum&quot;)] &lt;- &quot;forest_heavy_cs10&quot; Sweet. Next column.. 6.2.7 Setting cn2: You know the drill – I am sure you know how to read this code by now. # Brush-brush-weed-grass_mixture_with_brush_the_major_element (poor) landuse_lum$cn2[which(landuse_lum$name == &quot;rngb_lum&quot;)] &lt;- &quot;brush_p&quot; # Woods (poor) landuse_lum$cn2[which(landuse_lum$name == &quot;wetf_lum&quot;)] &lt;- &quot;wood_p&quot; # Paved_streets_and_roads;_open_ditches_(incl._right-of-way) landuse_lum$cn2[which(landuse_lum$name == &quot;utrn_lum&quot;)] &lt;- &quot;paveroad&quot; # Paved_parking_lots_roofs_driveways_etc_(excl_right-of-way) landuse_lum$cn2[which(landuse_lum$name == &quot;urml_lum&quot;)] &lt;- &quot;urban&quot; # Woods (fair) landuse_lum$cn2[which(landuse_lum$name == &quot;frst_lum&quot;)] &lt;- &quot;wood_f&quot; # Pasture_grassland_or_range-continuous_forage_for_grazing landuse_lum$cn2[which(landuse_lum$name == &quot;past_lum&quot;)] &lt;- &quot;pastg_g&quot; # Meadow-continuous_grass_protected_from_grazing_mowed_for_hay landuse_lum$cn2[which(landuse_lum$field_id %in% meadow_fields)] &lt;- &quot;pasth&quot; # Row_crops landuse_lum$cn2[which(landuse_lum$field_id %in% cons_fields)] &lt;- &quot;rc_conterres_g&quot; # Row_crops landuse_lum$cn2[which(landuse_lum$field_id %in% conv_fields)] &lt;- &quot;rc_strow_p&quot; 6.2.8 Setting cons_prac For this, we need to add some custom entries to the database: # TODO: remove temp!!!! cons_prac_path &lt;- &quot;model_data/cs10_setup/temp_cons_practice.lum&quot; cons_prac &lt;- readLines(cons_prac_path) cons_prac[1:3] %&gt;% print() ## [1] &quot;cons_practice.lum: written by SWAT+ editor v2.1.0 on 2023-03-31 08:13 for SWAT+ rev.60.5.4&quot; ## [2] &quot;name usle_p slp_len_max description&quot; ## [3] &quot;up_down_slope 1.00000 121.00000 Up_and_down_slope&quot; Let us do it in a way so that it is only added if it doesn’t exist yet: if(grepl(x = cons_prac, &quot;agri_conv&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;agri_conv 1.00000 60.00000 no_convervation&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;agri_part_conv&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;agri_part_conv 0.85000 60.00000 75_percent_convential&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;agri_half&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;agri_half 0.70000 50.00000 50_percent_convential&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;agri_part_cons&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;agri_part_cons 0.50000 30.00000 75_percent_consveration&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;agri_cons&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;agri_cons 0.30000 30.00000 100_percent_consveration&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;past_cons&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;past_cons 0.1 60 pasture&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;rngb_cons&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;rngb_cons 0.2 60 rangeland&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;frst_cons&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;frst_cons 0.1 60 forest&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;urml_cons&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;urml_cons 1 60 cs10urban&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;utrn_cons&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;utrn_cons 1 60 road&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;cs10_meadow&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;cs10_meadow 0.2 60 cs10_meadow&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;wetf_cons&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;wetf_cons 0.05 30 wetlands&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;cs10_sed_pond&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;cs10_sed_pond 0.1 30 cs10_sed_pond&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;cs10_cons_wetl&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;cs10_cons_wetl 0.1 30 cs10_cons_wetl&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;cs10_buff_grass&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;cs10_buff_grass 0.25 10 cs10_buff_grass&quot; cons_prac &lt;- c(cons_prac, entry) } if (grepl(x = cons_prac, &quot;cs_10_buff_wood&quot;) %&gt;% which %&gt;% length() == 0) { entry &lt;- &quot;cs_10_buff_wood 0.2 10 cs_10_buff_wood&quot; cons_prac &lt;- c(cons_prac, entry) } And write the updated file: writeLines(cons_prac, con = cons_prac_path) Now we need to define the 0, 25, 50, 75, 100 percent conventional crops. We can use our old “crop_fractions” dataframe: head(crop_fractions) ## # A tibble: 6 × 4 ## field conv cons meadow ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 a_025f_1 4 0 0 ## 2 a_025f_3 4 0 0 ## 3 a_025f_4 4 0 0 ## 4 a_025f_2 4 0 0 ## 5 a_105f_1 4 0 0 ## 6 a_105f_4 4 0 0 Lets derive which fields get classified as what p100_conv &lt;- crop_fractions %&gt;% filter(conv==4) %&gt;% dplyr::select(field) %&gt;% pull() p75_conv &lt;- crop_fractions %&gt;% filter(conv==3) %&gt;% dplyr::select(field) %&gt;% pull() p50_conv &lt;- crop_fractions %&gt;% filter(conv==2) %&gt;% dplyr::select(field) %&gt;% pull() p25_conv &lt;- crop_fractions %&gt;% filter(conv==1) %&gt;% dplyr::select(field) %&gt;% pull() p0_conv &lt;- crop_fractions %&gt;% filter(conv==0) %&gt;% dplyr::select(field) %&gt;% pull() Now we can assign the all the land uses # Agricultural landuse_lum$cons_prac[which(landuse_lum$field_id %in% p100_conv)] &lt;- &quot;agri_conv&quot; landuse_lum$cons_prac[which(landuse_lum$field_id %in% p75_conv)] &lt;- &quot;agri_part_conv&quot; landuse_lum$cons_prac[which(landuse_lum$field_id %in% p50_conv)] &lt;- &quot;agri_half&quot; landuse_lum$cons_prac[which(landuse_lum$field_id %in% p25_conv)] &lt;- &quot;agri_part_cons&quot; landuse_lum$cons_prac[which(landuse_lum$field_id %in% p0_conv)] &lt;- &quot;agri_cons&quot; # Meadow landuse_lum$cons_prac[which(field_class$meadow)] &lt;- &quot;cs10_meadow&quot; # Generic landuse_lum$cons_prac[which(landuse_lum$name == &quot;past_lum&quot;)] &lt;- &quot;past_cons&quot; landuse_lum$cons_prac[which(landuse_lum$name == &quot;rngb_lum&quot;)] &lt;- &quot;rngb_cons&quot; landuse_lum$cons_prac[which(landuse_lum$name == &quot;frst_lum&quot;)] &lt;- &quot;frst_cons&quot; landuse_lum$cons_prac[which(landuse_lum$name == &quot;urml_lum&quot;)] &lt;- &quot;urml_cons&quot; landuse_lum$cons_prac[which(landuse_lum$name == &quot;utrn_lum&quot;)] &lt;- &quot;utrn_cons&quot; landuse_lum$cons_prac[which(landuse_lum$name == &quot;wetf_lum&quot;)] &lt;- &quot;wetf_cons&quot; # Measures landuse_lum$cons_prac[which(landuse_lum$name == &quot;cs10_sed_pond&quot;)] &lt;- &quot;cs10_sed_pond&quot; landuse_lum$cons_prac[which(landuse_lum$name == &quot;cs10_cons_wetl&quot;)] &lt;- &quot;cs10_cons_wetl&quot; landuse_lum$cons_prac[which(landuse_lum$name == &quot;cs10_buff_grass&quot;)] &lt;- &quot;cs10_buff_grass&quot; landuse_lum$cons_prac[which(landuse_lum$name == &quot;cs_10_buff_wood&quot;)] &lt;- &quot;cs_10_buff_wood&quot; 6.2.9 Setting tile This column has already been completed by SWATbuildR in 2.3 6.2.10 Setting sep This column has been left as null 6.2.11 Setting vfs This column has been left as null 6.2.12 Setting grww This column has been left as null 6.2.13 Setting bmp This column has been left as null 6.3 Writing Changes We are done with our modifications however, we need to remove the field_id column landuse_lum &lt;- landuse_lum %&gt;% dplyr::select(-field_id) lets take a look at the final product: datatable(landuse_lum) Lets write out changes new_lum_path &lt;- &quot;model_data/cs10_setup/temp_lum_new.lum&quot; write.table(landuse_lum, file = new_lum_path, sep = &quot;\\t&quot;, quote = F, row.names = F) But wait – we need to keep that pesky header, otherwise the FarmR will be very angry with us. lum_lines &lt;- readLines(new_lum_path) header &lt;- &quot;header header header HEADER, delete me and you will regret it FOREVER!&quot; lum_lines2&lt;- c(header,lum_lines) writeLines(text = lum_lines2, con = new_lum_path) Done! References "],["scheduling-managment-with-swatfarmr.html", "Chapter 7 Scheduling Managment with SWATFarmR 7.1 Introduction 7.2 Pre-processing crop rotation 7.3 Initializing FarmR 7.4 Calculating Antecedent Precipitation Index 7.5 Scheduling Operations 7.6 Write Operations", " Chapter 7 Scheduling Managment with SWATFarmR 7.1 Introduction WIP: Every field in the OPTAIN SWAT setup needs its own management. We will use the SWATFarmR package to define it. 7.1.1 Pre-requirements The creation of management schedules with SWATfarmR requires a SWAT+ model setup created by the SWATbuildR package. We also require the following packages: require(DT) require(ggplot2) require(readr) require(stringr) require(magrittr) #remotes::install_github(&quot;chrisschuerz/SWATfarmR&quot;) require(SWATfarmR) 7.2 Pre-processing crop rotation This OPTAIN-provided workflow pre-processes our crop rotation data into a SWATfarmR compatible format. Authored by Michael Strauch, modified by Moritz Shore It requires the following packages require(sf) require(tidyverse) require(lubridate) require(reshape2) require(remotes) require(dplyr) require(data.table) And the following functions: source(&#39;model_data/swat_farmR/functions_write_SWATfarmR_input.R&#39;) 7.2.1 Input files 7.2.1.1 Land use map with crop information This map has the following requirements: The map must contain the land use of each hru. In case of cropland, the names must be unique for each field (e.g., ‘field_1’, ‘field_2’, etc.) The map must also contain crop infos for the period 1988 to 2020 (or 2021 if crop info available). This requires an extrapolation of the available crop sequences (the sequences derived from remote-sensing based crop classification or local data). The extrapolated crop sequence for 33 years will be also used for running climate scenarios and must not contain any gaps. That means, gaps have to be closed manually! The year columns must be named y_1988, y_1989, etc. The crop infos for each year must match the crop_mgt names in the management operation schedules (provided in a .csv file, see below) see also section 4.1 of the modelling protocol (ref) lu_shp &lt;- &#39;model_data/input/crop/land_with_cr.shp&#39; lu &lt;- st_drop_geometry(read_sf(lu_shp)) datatable( lu %&gt;% head(50), extensions = &quot;Scroller&quot;, options = list(scrollY = 200, scroller = TRUE) ) 7.2.1.2 Management operation schedules for each crop ..or, if available, crop-management type. All schedules must be compiled in one csv file (see example in demo data and study also section 4.2 of the modelling protocol) ‘crop_mgt’ must start with the 4-character SWAT crop names (any further management specification is optional). Each schedule must contain a ‘skip’ line to indicate the change of years. The ‘skip’ line should never be the last line of a schedule. mgt_csv &lt;- &#39;model_data/input/management/mgt_crops_CS10.csv&#39; mgt_crop &lt;- read.csv(mgt_csv) datatable(mgt_crop, extensions = &quot;Scroller&quot;, options = list(scrollY = 200, scroller = TRUE)) 7.2.1.3 Management operation schedules for generic land-use classes Usually all non-cropland classes with vegetation cover here, all schedules must be provided already in the SWATfarmR input format. lu_generic_csv &lt;- &#39;model_data/input/management/farmR_generic_CS10.csv&#39; # generic land use management .csv table mgt_generic &lt;- read.csv(lu_generic_csv) datatable(mgt_generic) 7.2.2 Settings 7.2.2.1 Simulation Period start_y &lt;- 1988 # starting year (consider at least 3 years for warm-up!) end_y &lt;- 2020 # ending year 7.2.2.2 Prefix of cropland hrus all names of hrus with a crop rotation must begin with this prefix in column ‘lu’ of your land use hru_crops &lt;- &#39;a_&#39; 7.2.2.3 Multi-year farmland grass Did you define any multi-year farmland grass schedules? ‘y’ (yes), ‘n’ (no) m_yr_sch_existing &lt;- &#39;n&#39; If yes, define also the following variables. If not, skip next four lines crop_myr &lt;- &#39;past&#39; # name of your farmland grass Maximum number of years farmland grass can grow before it is killed (should be &lt;8) max_yr &lt;- 5 Do your multi-year farmland grass schedules consider the type of the following crop (summer or winter crop)? (e.g., a ’_1.5yr’ schedule with a kill op in spring allows for planting a summer crop immediately afterwards) If yes, you must define your summer crops crop_s &lt;- c(&#39;sgbt&#39;,&#39;csil&#39;,&#39;barl&#39;) Do your summer crop schedules usually start with an operation in autumn (e.g. tillage)? To combine them with farmland grass, it is necessary that you provide ‘half-year-schedules’ (‘half-year-schedules’ are additional summer crop schedules without operations in autumn) The adapted schedules should be added to the crop management table with suffix ’_0.5yr’ (e.g. ‘csil_0.5yr’) If additional ‘half-year-schedules’ are not needed, because your normal summer crop schedules do not start in autumn, type ‘n’ additional_h_yr_sch_existing &lt;- &#39;n&#39; # &#39;y&#39; (yes), &#39;n&#39; (no) 7.2.3 Checks Check for correct positioning of ‘skip’ line check_skip &lt;- check_skip_position() ## [1] &quot;Check successfull&quot; Check for date conflicts in single crop schedules check_date_conflicts1() ## [1] &quot;check single schedule for crop 1&quot; ## [1] &quot;check single schedule for crop 2&quot; ## [1] &quot;check single schedule for crop 3&quot; ## [1] &quot;check single schedule for crop 4&quot; ## [1] &quot;check single schedule for crop 5&quot; ## [1] &quot;check single schedule for crop 6&quot; ## [1] &quot;No conflicts detected :)&quot; Build schedules for crop sequences (Messages disabled) rota_schedules &lt;- build_rotation_schedules() Check for date conflicts in the full rotation schedule. (Messages disabled) check_date_conflicts2() Solve minor date conflicts (where only a few days/weeks are overlapping) (Messages disabled) rota_schedules &lt;- solve_date_conflicts() Check again for date conflicts (Messages disabled) check_date_conflicts2() 7.2.4 Writing input data Write the SWAT farmR input table write_farmR_input() ## [[1]] ## [1] &quot;The SWATfarmR input is written to &#39;model_data/input/management/farmR_input.csv&#39;.&quot; ## ## [[2]] ## [1] &quot;If appropriate, add management schedules for generic land covers, such as orchards, pastures and meadows.&quot; ## ## [[3]] ## [1] &quot;(example schedules for generic land covers in SWATfarmR format are provided in farmR_lulc_generic.csv)&quot; ## ## [[4]] ## [1] &quot;Use this file as input for the SWATfarmR package.&quot; The output of this pre-processing stage is loaded in from this file: farmR_input &lt;- readr::read_csv(&quot;model_data/input/management/farmR_input.csv&quot;, show_col_types = F) datatable( head(farmR_input, 50), extensions = &quot;Scroller&quot;, options = list(scrollY = 200, scroller = TRUE) ) TODO: Figure out why this is an issue. Are you using the wrong buildR output as source material for the crop generation? We need to fix the land use name, which entails replacing the _drn_lum with just _lum for all the agricultural fields. This is because land.shp from buildR does not include the _drn for some reason # TODO: Figure out why this is an issue. Are you using the wrong buildR output # as source material for the crop generation? farmR_input2 &lt;- farmR_input %&gt;% filter(grepl(x = land_use, &quot;a_&quot;)) %&gt;% mutate(land_use = str_replace(.$land_use, &quot;_lum&quot;, &quot;_drn_lum&quot;)) farmR_input3 &lt;- farmR_input %&gt;% filter(!grepl(x = land_use, &quot;a_&quot;)) farmR_input4 &lt;- rbind(farmR_input2, farmR_input3) write_csv(farmR_input4, file =&quot;model_data/input/management/farmR_input2.csv&quot;) rm(farmR_input, farmR_input2, farmR_input3, farmR_input4) # Yes I am aware that code is bad and ugly. 7.3 Initializing FarmR If the FarmR has never been initialized, then use new_farmr() and read_management(), otherwise load_farmr(). EVAL FALSE as BuildR script is still broken project_path &lt;- &quot;model_data/cs10_setup&quot; SWATfarmR::new_farmr(project_name = &quot;cs10&quot;, project_path = project_path ) #load_farmr(...) cs10$read_management(file = &quot;farmR_input/farmR_input2.csv&quot;) 7.4 Calculating Antecedent Precipitation Index USING TEMPORARY API: This needs to be replaced with a proper model. See issue #17 EVAL FALSE as BuildR script is still broken # Load dplyr. We will use functions such as &#39;mutate&#39; and &#39;select&#39;. library(dplyr) # Extract the precipitation from the farmr project pcp &lt;- cs10$.data$variables$pcp # Extract the hydrologic soil group values for all HRUs hsg &lt;- select(cs10$.data$meta$hru_attributes, hru, hyd_grp) # Calculate api values for the hsg classes A to D api_A &lt;- variable_decay(variable = pcp, n_steps = -5, decay_rate = 1) api_B &lt;- variable_decay(variable = pcp, n_steps = -5, decay_rate = 0.8) api_C &lt;- variable_decay(variable = pcp, n_steps = -5, decay_rate = 0.7) api_D &lt;- variable_decay(variable = pcp, n_steps = -5, decay_rate = 0.5) # Bind the data together into one api table and name them with the hsgs api &lt;- bind_cols(api_A, api_B, api_C, api_D) names(api) &lt;- c(&#39;api_A&#39;, &#39;api_B&#39;, &#39;api_C&#39;, &#39;api_D&#39;) # To add the variable to the farmR you have to tell it which variables are # assigned to which HRUs hru_asgn &lt;- mutate(hsg, api = paste0(&#39;api_&#39;, hyd_grp)) %&gt;% select(hru, api) # Add the variable api to the farmR project cs10$add_variable(data = api, name = &#39;api&#39;, assign_unit = hru_asgn, overwrite = T) From (patrignani2020?): The API is a well-known, parsimonious, recursive model for predicting soil moisture solely based on precipitation records. The API is commonly implemented using daily precipitation records, but it is possible to work at finer temporal scales (e.g. hourly) if both precipitation (model input) and soil moisture (for validation purposes) are available. The equation describing the simples version of the model is: \\[API_{t} = \\alpha API_{t-1} + P_t\\] \\(API_t\\): Soil water content at time \\(t\\) (today) \\(API_{t-1}\\): Soil water content at time \\(t-1\\) (yesterday) \\(\\alpha\\): Loss coefficient. Range between 0 and 1 \\(P_t\\): Precipitation at time \\(t\\) (today) Following Python code modified from (patrignani2020?) (read more) Just do it in R… bokeh wont place nice and we need to do some annoying time date stuff …. 7.5 Scheduling Operations EVAL FALSE as BuildR script is still broken cs10$schedule_operations(start_year = 2010, end_year = 2020, n_schedule = 2) 7.6 Write Operations EVAL FALSE as BuildR script is still broken We cannot write from 1988 as it is limited to our climate data, which currently only spans back to 2010 cs10$write_operations(start_year = 2010, end_year = 2020) "],["wip.html", "Chapter 8 WIP 8.1 WIP", " Chapter 8 WIP 8.1 WIP 8.1.1 Channel parameters revised This an ongoing unresolved issue #49 8.1.2 Crop parameters verified 8.1.3 Soil physical parameters in final form 8.1.4 Soil chemical parameters in final form 8.1.5 Impoundment parameters defined 8.1.6 Water diversions defined 8.1.7 Point sources parameters added 8.1.8 Tile drainage parameters defined 8.1.9 Atmospheric deposition defined 8.1.10 Additional settings verified "]]
